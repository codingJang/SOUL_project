{
  "trial_data": [
    [
      "{\n  \"stub\": false,\n  \"trainable_name\": \"SAC\",\n  \"trial_id\": \"20027_00000\",\n  \"storage\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059512030000000000008c1b7261792e747261696e2e5f696e7465726e616c2e73746f72616765948c0e53746f72616765436f6e746578749493942981947d94288c12637573746f6d5f66735f70726f766964656494898c1273746f726167655f6c6f63616c5f70617468948c227e2f7261795f726573756c74732f706f6c69746963735f656e7669726f6e6d656e74948c0c73746f726167655f706174689468078c136578706572696d656e745f6469725f6e616d65948c03534143948c0e747269616c5f6469725f6e616d65948c3a5341435f706f6c69746963735f656e7669726f6e6d656e745f32303032375f30303030305f305f323032332d31312d31365f32322d31382d3239948c1863757272656e745f636865636b706f696e745f696e646578944affffffff8c0b73796e635f636f6e666967948c097261792e747261696e948c0a53796e63436f6e6669679493942981947d94288c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d08078c0e73796e635f61727469666163747394898c1c73796e635f6172746966616374735f6f6e5f636865636b706f696e7494888c0a75706c6f61645f646972948c0a44455052454341544544948c0673796e6365729468198c1273796e635f6f6e5f636865636b706f696e7494681975628c1273746f726167655f66696c6573797374656d948c0b70796172726f772e5f6673948c1c4c6f63616c46696c6553797374656d2e5f7265636f6e7374727563749493947d948c087573655f6d6d6170948973859452948c0f73746f726167655f66735f70617468948c322f55736572732f6a616e672d79656a756e2f7261795f726573756c74732f706f6c69746963735f656e7669726f6e6d656e7494681a68008c115f46696c6573797374656d53796e6365729493942981947d9428681c682368144d2c0168154d08078c116c6173745f73796e635f75705f74696d659447fff00000000000008c136c6173745f73796e635f646f776e5f74696d659447fff00000000000008c0d5f73796e635f70726f63657373944e8c0c5f63757272656e745f636d64944e756275622e\"\n  },\n  \"config\": {\n    \"extra_python_environs_for_driver\": {},\n    \"extra_python_environs_for_worker\": {},\n    \"num_gpus\": 0,\n    \"num_cpus_per_worker\": 1,\n    \"num_gpus_per_worker\": 0,\n    \"_fake_gpus\": false,\n    \"num_learner_workers\": 0,\n    \"num_gpus_per_learner_worker\": 0,\n    \"num_cpus_per_learner_worker\": 1,\n    \"local_gpu_idx\": 0,\n    \"custom_resources_per_worker\": {},\n    \"placement_strategy\": \"PACK\",\n    \"eager_tracing\": true,\n    \"eager_max_retraces\": 20,\n    \"tf_session_args\": {\n      \"intra_op_parallelism_threads\": 2,\n      \"inter_op_parallelism_threads\": 2,\n      \"gpu_options\": {\n        \"allow_growth\": true\n      },\n      \"log_device_placement\": false,\n      \"device_count\": {\n        \"CPU\": 1\n      },\n      \"allow_soft_placement\": true\n    },\n    \"local_tf_session_args\": {\n      \"intra_op_parallelism_threads\": 8,\n      \"inter_op_parallelism_threads\": 8\n    },\n    \"torch_compile_learner\": false,\n    \"torch_compile_learner_what_to_compile\": \"forward_train\",\n    \"torch_compile_learner_dynamo_backend\": \"aot_eager\",\n    \"torch_compile_learner_dynamo_mode\": null,\n    \"torch_compile_worker\": false,\n    \"torch_compile_worker_dynamo_backend\": \"aot_eager\",\n    \"torch_compile_worker_dynamo_mode\": null,\n    \"env\": \"politics_environment\",\n    \"env_config\": {},\n    \"observation_space\": null,\n    \"action_space\": null,\n    \"env_task_fn\": null,\n    \"render_env\": false,\n    \"clip_rewards\": null,\n    \"normalize_actions\": true,\n    \"clip_actions\": true,\n    \"disable_env_checking\": false,\n    \"auto_wrap_old_gym_envs\": true,\n    \"action_mask_key\": \"action_mask\",\n    \"_is_atari\": null,\n    \"env_runner_cls\": null,\n    \"num_envs_per_worker\": 1,\n    \"sample_collector\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n    },\n    \"sample_async\": false,\n    \"enable_connectors\": true,\n    \"update_worker_filter_stats\": true,\n    \"use_worker_filter_stats\": true,\n    \"rollout_fragment_length\": 128,\n    \"batch_mode\": \"truncate_episodes\",\n    \"remote_worker_envs\": false,\n    \"remote_env_batch_wait_ms\": 0,\n    \"validate_workers_after_construction\": true,\n    \"preprocessor_pref\": \"deepmind\",\n    \"observation_filter\": \"NoFilter\",\n    \"compress_observations\": false,\n    \"enable_tf1_exec_eagerly\": false,\n    \"sampler_perf_stats_ema_coef\": null,\n    \"gamma\": 0.9,\n    \"lr\": 0.01,\n    \"grad_clip\": null,\n    \"grad_clip_by\": \"global_norm\",\n    \"train_batch_size\": 256,\n    \"model\": {\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"tanh\",\n      \"conv_filters\": null,\n      \"conv_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": \"relu\",\n      \"free_log_std\": false,\n      \"no_final_linear\": false,\n      \"vf_share_layers\": true,\n      \"use_lstm\": false,\n      \"max_seq_len\": 20,\n      \"lstm_cell_size\": 256,\n      \"lstm_use_prev_action\": false,\n      \"lstm_use_prev_reward\": false,\n      \"_time_major\": false,\n      \"use_attention\": false,\n      \"attention_num_transformer_units\": 1,\n      \"attention_dim\": 64,\n      \"attention_num_heads\": 1,\n      \"attention_head_dim\": 32,\n      \"attention_memory_inference\": 50,\n      \"attention_memory_training\": 50,\n      \"attention_position_wise_mlp_dim\": 32,\n      \"attention_init_gru_gate_bias\": 2.0,\n      \"attention_use_n_prev_actions\": 0,\n      \"attention_use_n_prev_rewards\": 0,\n      \"framestack\": true,\n      \"dim\": 84,\n      \"grayscale\": false,\n      \"zero_mean\": true,\n      \"custom_model\": null,\n      \"custom_model_config\": {},\n      \"custom_action_dist\": null,\n      \"custom_preprocessor\": null,\n      \"encoder_latent_dim\": null,\n      \"always_check_shapes\": false,\n      \"lstm_use_prev_action_reward\": -1,\n      \"_use_default_native_models\": -1\n    },\n    \"optimizer\": {},\n    \"max_requests_in_flight_per_sampler_worker\": 2,\n    \"_learner_class\": null,\n    \"_enable_learner_api\": false,\n    \"explore\": true,\n    \"exploration_config\": {\n      \"type\": \"StochasticSampling\"\n    },\n    \"algorithm_config_overrides_per_module\": {},\n    \"policy_map_capacity\": 100,\n    \"policy_mapping_fn\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059531020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b034b014b4f43047c005300944e8594298c086167656e745f6964948c0461726773948c066b77617267739487948c692f55736572732f6a616e672d79656a756e2f50726f6a656374732f5653436f646550726f6a656374732f534f554c5f70726f6a6563742f536f757263652f524c6c696250726163746963652f524c6c696270726163746963655f706f6c69746963735f656e762e7079948c083c6c616d6264613e944b2f4300942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680e754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f736574737461746594939468197d947d94286815680f8c0c5f5f7175616c6e616d655f5f94680f8c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468168c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n    },\n    \"policies_to_train\": null,\n    \"policy_states_are_swappable\": false,\n    \"observation_fn\": null,\n    \"count_steps_by\": \"env_steps\",\n    \"input_config\": {},\n    \"actions_in_input_normalized\": false,\n    \"postprocess_inputs\": false,\n    \"shuffle_buffer_size\": 0,\n    \"output\": null,\n    \"output_config\": {},\n    \"output_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"output_max_file_size\": 67108864,\n    \"offline_sampling\": false,\n    \"evaluation_interval\": null,\n    \"evaluation_duration\": 10,\n    \"evaluation_duration_unit\": \"episodes\",\n    \"evaluation_sample_timeout_s\": 180.0,\n    \"evaluation_parallel_to_training\": false,\n    \"evaluation_config\": null,\n    \"off_policy_estimation_methods\": {},\n    \"ope_split_batch_by_episode\": true,\n    \"evaluation_num_workers\": 0,\n    \"always_attach_evaluation_results\": false,\n    \"enable_async_evaluation\": false,\n    \"in_evaluation\": false,\n    \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n    \"keep_per_episode_custom_metrics\": false,\n    \"metrics_episode_collection_timeout_s\": 60.0,\n    \"metrics_num_episodes_for_smoothing\": 100,\n    \"min_time_s_per_iteration\": 1,\n    \"min_train_timesteps_per_iteration\": 0,\n    \"min_sample_timesteps_per_iteration\": 100,\n    \"export_native_model_files\": false,\n    \"checkpoint_trainable_policies_only\": false,\n    \"logger_creator\": null,\n    \"logger_config\": null,\n    \"log_level\": \"ERROR\",\n    \"log_sys_usage\": true,\n    \"fake_sampler\": false,\n    \"seed\": null,\n    \"ignore_worker_failures\": false,\n    \"recreate_failed_workers\": false,\n    \"max_num_worker_restarts\": 1000,\n    \"delay_between_worker_restarts_s\": 60.0,\n    \"restart_failed_sub_environments\": false,\n    \"num_consecutive_worker_failures_tolerance\": 100,\n    \"worker_health_probe_timeout_s\": 60,\n    \"worker_restore_timeout_s\": 1800,\n    \"rl_module_spec\": null,\n    \"_enable_rl_module_api\": false,\n    \"_AlgorithmConfig__prior_exploration_config\": null,\n    \"_tf_policy_handles_more_than_one_loss\": false,\n    \"_disable_preprocessor_api\": false,\n    \"_disable_action_flattening\": false,\n    \"_disable_execution_plan_api\": true,\n    \"_disable_initialize_loss_from_dummy_batch\": false,\n    \"simple_optimizer\": -1,\n    \"policy_map_cache\": -1,\n    \"worker_cls\": -1,\n    \"synchronize_filters\": -1,\n    \"replay_sequence_length\": null,\n    \"twin_q\": true,\n    \"q_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"policy_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"tau\": 0.005,\n    \"initial_alpha\": 1.0,\n    \"target_entropy\": \"auto\",\n    \"n_step\": 1,\n    \"replay_buffer_config\": {\n      \"_enable_replay_buffer_api\": true,\n      \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n      \"capacity\": 1000000,\n      \"prioritized_replay\": false,\n      \"prioritized_replay_alpha\": 0.6,\n      \"prioritized_replay_beta\": 0.4,\n      \"prioritized_replay_eps\": 1e-06,\n      \"worker_side_prioritization\": false\n    },\n    \"store_buffer_in_checkpoints\": false,\n    \"training_intensity\": null,\n    \"optimization\": {\n      \"actor_learning_rate\": 0.0003,\n      \"critic_learning_rate\": 0.0003,\n      \"entropy_learning_rate\": 0.0003\n    },\n    \"target_network_update_freq\": 0,\n    \"num_steps_sampled_before_learning_starts\": 1500,\n    \"_deterministic_loss\": false,\n    \"_use_beta_distribution\": false,\n    \"use_state_preprocessor\": -1,\n    \"worker_side_prioritization\": -1,\n    \"input\": \"sampler\",\n    \"policies\": {\n      \"agent_0\": [\n        null,\n        {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"800595f4010000000000008c1467796d6e617369756d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994680593948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0d626f756e6465645f62656c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289609000000000000000101010101010101019468078c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b0985948c014394749452948c0d626f756e6465645f61626f7665946810289609000000000000000101010101010101019468144b0985946818749452948c065f7368617065944b0985948c036c6f77946810289624000000000000000000000000000000000000000000000000000000000000000000000000000000000000009468078c02663494898887945294284b03680b4e4e4e4affffffff4affffffff4b007494624b0985946818749452948c0468696768946810289624000000000000000000004000000040000000400000004000000040000000400000004000000040000000409468264b0985946818749452948c086c6f775f72657072948c03302e30948c09686967685f72657072948c03322e30948c0a5f6e705f72616e646f6d944e75622e\"\n        },\n        {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"800595d7010000000000008c1467796d6e617369756d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994680593948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0d626f756e6465645f62656c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289606000000000000000000000000009468078c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b0685948c014394749452948c0d626f756e6465645f61626f7665946810289606000000000000000000000000009468144b0685946818749452948c065f7368617065944b0685948c036c6f7794681028961800000000000000000080ff000080ff000080ff000080ff000080ff000080ff9468078c02663494898887945294284b03680b4e4e4e4affffffff4affffffff4b007494624b0685946818749452948c0468696768946810289618000000000000000000807f0000807f0000807f0000807f0000807f0000807f9468264b0685946818749452948c086c6f775f72657072948c042d696e66948c09686967685f72657072948c03696e66948c0a5f6e705f72616e646f6d944e75622e\"\n        },\n        {}\n      ],\n      \"agent_1\": [\n        null,\n        {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"800595f4010000000000008c1467796d6e617369756d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994680593948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0d626f756e6465645f62656c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289609000000000000000101010101010101019468078c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b0985948c014394749452948c0d626f756e6465645f61626f7665946810289609000000000000000101010101010101019468144b0985946818749452948c065f7368617065944b0985948c036c6f77946810289624000000000000000000000000000000000000000000000000000000000000000000000000000000000000009468078c02663494898887945294284b03680b4e4e4e4affffffff4affffffff4b007494624b0985946818749452948c0468696768946810289624000000000000000000004000000040000000400000004000000040000000400000004000000040000000409468264b0985946818749452948c086c6f775f72657072948c03302e30948c09686967685f72657072948c03322e30948c0a5f6e705f72616e646f6d944e75622e\"\n        },\n        {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"800595d7010000000000008c1467796d6e617369756d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994680593948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0d626f756e6465645f62656c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289606000000000000000000000000009468078c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b0685948c014394749452948c0d626f756e6465645f61626f7665946810289606000000000000000000000000009468144b0685946818749452948c065f7368617065944b0685948c036c6f7794681028961800000000000000000080ff000080ff000080ff000080ff000080ff000080ff9468078c02663494898887945294284b03680b4e4e4e4affffffff4affffffff4b007494624b0685946818749452948c0468696768946810289618000000000000000000807f0000807f0000807f0000807f0000807f0000807f9468264b0685946818749452948c086c6f775f72657072948c042d696e66948c09686967685f72657072948c03696e66948c0a5f6e705f72616e646f6d944e75622e\"\n        },\n        {}\n      ],\n      \"agent_2\": [\n        null,\n        {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"800595f4010000000000008c1467796d6e617369756d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994680593948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0d626f756e6465645f62656c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289609000000000000000101010101010101019468078c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b0985948c014394749452948c0d626f756e6465645f61626f7665946810289609000000000000000101010101010101019468144b0985946818749452948c065f7368617065944b0985948c036c6f77946810289624000000000000000000000000000000000000000000000000000000000000000000000000000000000000009468078c02663494898887945294284b03680b4e4e4e4affffffff4affffffff4b007494624b0985946818749452948c0468696768946810289624000000000000000000004000000040000000400000004000000040000000400000004000000040000000409468264b0985946818749452948c086c6f775f72657072948c03302e30948c09686967685f72657072948c03322e30948c0a5f6e705f72616e646f6d944e75622e\"\n        },\n        {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"800595d7010000000000008c1467796d6e617369756d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994680593948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0d626f756e6465645f62656c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289606000000000000000000000000009468078c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b0685948c014394749452948c0d626f756e6465645f61626f7665946810289606000000000000000000000000009468144b0685946818749452948c065f7368617065944b0685948c036c6f7794681028961800000000000000000080ff000080ff000080ff000080ff000080ff000080ff9468078c02663494898887945294284b03680b4e4e4e4affffffff4affffffff4b007494624b0685946818749452948c0468696768946810289618000000000000000000807f0000807f0000807f0000807f0000807f0000807f9468264b0685946818749452948c086c6f775f72657072948c042d696e66948c09686967685f72657072948c03696e66948c0a5f6e705f72616e646f6d944e75622e\"\n        },\n        {}\n      ]\n    },\n    \"callbacks\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059537000000000000008c1e7261792e726c6c69622e616c676f726974686d732e63616c6c6261636b73948c1044656661756c7443616c6c6261636b739493942e\"\n    },\n    \"create_env_on_driver\": false,\n    \"custom_eval_function\": null,\n    \"framework\": \"torch\",\n    \"num_cpus_for_driver\": 1,\n    \"num_workers\": 7\n  },\n  \"_Trial__unresolved_config\": {\n    \"extra_python_environs_for_driver\": {},\n    \"extra_python_environs_for_worker\": {},\n    \"num_gpus\": 0,\n    \"num_cpus_per_worker\": 1,\n    \"num_gpus_per_worker\": 0,\n    \"_fake_gpus\": false,\n    \"num_learner_workers\": 0,\n    \"num_gpus_per_learner_worker\": 0,\n    \"num_cpus_per_learner_worker\": 1,\n    \"local_gpu_idx\": 0,\n    \"custom_resources_per_worker\": {},\n    \"placement_strategy\": \"PACK\",\n    \"eager_tracing\": true,\n    \"eager_max_retraces\": 20,\n    \"tf_session_args\": {\n      \"intra_op_parallelism_threads\": 2,\n      \"inter_op_parallelism_threads\": 2,\n      \"gpu_options\": {\n        \"allow_growth\": true\n      },\n      \"log_device_placement\": false,\n      \"device_count\": {\n        \"CPU\": 1\n      },\n      \"allow_soft_placement\": true\n    },\n    \"local_tf_session_args\": {\n      \"intra_op_parallelism_threads\": 8,\n      \"inter_op_parallelism_threads\": 8\n    },\n    \"torch_compile_learner\": false,\n    \"torch_compile_learner_what_to_compile\": \"forward_train\",\n    \"torch_compile_learner_dynamo_backend\": \"aot_eager\",\n    \"torch_compile_learner_dynamo_mode\": null,\n    \"torch_compile_worker\": false,\n    \"torch_compile_worker_dynamo_backend\": \"aot_eager\",\n    \"torch_compile_worker_dynamo_mode\": null,\n    \"env\": \"politics_environment\",\n    \"env_config\": {},\n    \"observation_space\": null,\n    \"action_space\": null,\n    \"env_task_fn\": null,\n    \"render_env\": false,\n    \"clip_rewards\": null,\n    \"normalize_actions\": true,\n    \"clip_actions\": true,\n    \"disable_env_checking\": false,\n    \"auto_wrap_old_gym_envs\": true,\n    \"action_mask_key\": \"action_mask\",\n    \"_is_atari\": null,\n    \"env_runner_cls\": null,\n    \"num_envs_per_worker\": 1,\n    \"sample_collector\": [\n      \"__ref_ph\",\n      \"f176708f\"\n    ],\n    \"sample_async\": false,\n    \"enable_connectors\": true,\n    \"update_worker_filter_stats\": true,\n    \"use_worker_filter_stats\": true,\n    \"rollout_fragment_length\": 128,\n    \"batch_mode\": \"truncate_episodes\",\n    \"remote_worker_envs\": false,\n    \"remote_env_batch_wait_ms\": 0,\n    \"validate_workers_after_construction\": true,\n    \"preprocessor_pref\": \"deepmind\",\n    \"observation_filter\": \"NoFilter\",\n    \"compress_observations\": false,\n    \"enable_tf1_exec_eagerly\": false,\n    \"sampler_perf_stats_ema_coef\": null,\n    \"gamma\": 0.9,\n    \"lr\": 0.01,\n    \"grad_clip\": null,\n    \"grad_clip_by\": \"global_norm\",\n    \"train_batch_size\": 256,\n    \"model\": {\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"tanh\",\n      \"conv_filters\": null,\n      \"conv_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": \"relu\",\n      \"free_log_std\": false,\n      \"no_final_linear\": false,\n      \"vf_share_layers\": true,\n      \"use_lstm\": false,\n      \"max_seq_len\": 20,\n      \"lstm_cell_size\": 256,\n      \"lstm_use_prev_action\": false,\n      \"lstm_use_prev_reward\": false,\n      \"_time_major\": false,\n      \"use_attention\": false,\n      \"attention_num_transformer_units\": 1,\n      \"attention_dim\": 64,\n      \"attention_num_heads\": 1,\n      \"attention_head_dim\": 32,\n      \"attention_memory_inference\": 50,\n      \"attention_memory_training\": 50,\n      \"attention_position_wise_mlp_dim\": 32,\n      \"attention_init_gru_gate_bias\": 2.0,\n      \"attention_use_n_prev_actions\": 0,\n      \"attention_use_n_prev_rewards\": 0,\n      \"framestack\": true,\n      \"dim\": 84,\n      \"grayscale\": false,\n      \"zero_mean\": true,\n      \"custom_model\": null,\n      \"custom_model_config\": {},\n      \"custom_action_dist\": null,\n      \"custom_preprocessor\": null,\n      \"encoder_latent_dim\": null,\n      \"always_check_shapes\": false,\n      \"lstm_use_prev_action_reward\": -1,\n      \"_use_default_native_models\": -1\n    },\n    \"optimizer\": {},\n    \"max_requests_in_flight_per_sampler_worker\": 2,\n    \"_learner_class\": null,\n    \"_enable_learner_api\": false,\n    \"explore\": true,\n    \"exploration_config\": {\n      \"type\": \"StochasticSampling\"\n    },\n    \"algorithm_config_overrides_per_module\": {},\n    \"policy_map_capacity\": 100,\n    \"policy_mapping_fn\": [\n      \"__ref_ph\",\n      \"cdf20c8b\"\n    ],\n    \"policies_to_train\": null,\n    \"policy_states_are_swappable\": false,\n    \"observation_fn\": null,\n    \"count_steps_by\": \"env_steps\",\n    \"input_config\": {},\n    \"actions_in_input_normalized\": false,\n    \"postprocess_inputs\": false,\n    \"shuffle_buffer_size\": 0,\n    \"output\": null,\n    \"output_config\": {},\n    \"output_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"output_max_file_size\": 67108864,\n    \"offline_sampling\": false,\n    \"evaluation_interval\": null,\n    \"evaluation_duration\": 10,\n    \"evaluation_duration_unit\": \"episodes\",\n    \"evaluation_sample_timeout_s\": 180.0,\n    \"evaluation_parallel_to_training\": false,\n    \"evaluation_config\": null,\n    \"off_policy_estimation_methods\": {},\n    \"ope_split_batch_by_episode\": true,\n    \"evaluation_num_workers\": 0,\n    \"always_attach_evaluation_results\": false,\n    \"enable_async_evaluation\": false,\n    \"in_evaluation\": false,\n    \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n    \"keep_per_episode_custom_metrics\": false,\n    \"metrics_episode_collection_timeout_s\": 60.0,\n    \"metrics_num_episodes_for_smoothing\": 100,\n    \"min_time_s_per_iteration\": 1,\n    \"min_train_timesteps_per_iteration\": 0,\n    \"min_sample_timesteps_per_iteration\": 100,\n    \"export_native_model_files\": false,\n    \"checkpoint_trainable_policies_only\": false,\n    \"logger_creator\": null,\n    \"logger_config\": null,\n    \"log_level\": \"ERROR\",\n    \"log_sys_usage\": true,\n    \"fake_sampler\": false,\n    \"seed\": null,\n    \"ignore_worker_failures\": false,\n    \"recreate_failed_workers\": false,\n    \"max_num_worker_restarts\": 1000,\n    \"delay_between_worker_restarts_s\": 60.0,\n    \"restart_failed_sub_environments\": false,\n    \"num_consecutive_worker_failures_tolerance\": 100,\n    \"worker_health_probe_timeout_s\": 60,\n    \"worker_restore_timeout_s\": 1800,\n    \"rl_module_spec\": null,\n    \"_enable_rl_module_api\": false,\n    \"_AlgorithmConfig__prior_exploration_config\": null,\n    \"_tf_policy_handles_more_than_one_loss\": false,\n    \"_disable_preprocessor_api\": false,\n    \"_disable_action_flattening\": false,\n    \"_disable_execution_plan_api\": true,\n    \"_disable_initialize_loss_from_dummy_batch\": false,\n    \"simple_optimizer\": -1,\n    \"policy_map_cache\": -1,\n    \"worker_cls\": -1,\n    \"synchronize_filters\": -1,\n    \"replay_sequence_length\": null,\n    \"twin_q\": true,\n    \"q_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"policy_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"tau\": 0.005,\n    \"initial_alpha\": 1.0,\n    \"target_entropy\": \"auto\",\n    \"n_step\": 1,\n    \"replay_buffer_config\": {\n      \"_enable_replay_buffer_api\": true,\n      \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n      \"capacity\": 1000000,\n      \"prioritized_replay\": false,\n      \"prioritized_replay_alpha\": 0.6,\n      \"prioritized_replay_beta\": 0.4,\n      \"prioritized_replay_eps\": 1e-06,\n      \"worker_side_prioritization\": false\n    },\n    \"store_buffer_in_checkpoints\": false,\n    \"training_intensity\": null,\n    \"optimization\": {\n      \"actor_learning_rate\": 0.0003,\n      \"critic_learning_rate\": 0.0003,\n      \"entropy_learning_rate\": 0.0003\n    },\n    \"target_network_update_freq\": 0,\n    \"num_steps_sampled_before_learning_starts\": 1500,\n    \"_deterministic_loss\": false,\n    \"_use_beta_distribution\": false,\n    \"use_state_preprocessor\": -1,\n    \"worker_side_prioritization\": -1,\n    \"input\": \"sampler\",\n    \"policies\": {\n      \"agent_0\": [\n        null,\n        [\n          \"__ref_ph\",\n          \"72e6d4a6\"\n        ],\n        [\n          \"__ref_ph\",\n          \"eb329df1\"\n        ],\n        {}\n      ],\n      \"agent_1\": [\n        null,\n        [\n          \"__ref_ph\",\n          \"f64c831b\"\n        ],\n        [\n          \"__ref_ph\",\n          \"a094dd64\"\n        ],\n        {}\n      ],\n      \"agent_2\": [\n        null,\n        [\n          \"__ref_ph\",\n          \"2cf9fe44\"\n        ],\n        [\n          \"__ref_ph\",\n          \"97b7f2ec\"\n        ],\n        {}\n      ]\n    },\n    \"callbacks\": [\n      \"__ref_ph\",\n      \"8913b504\"\n    ],\n    \"create_env_on_driver\": false,\n    \"custom_eval_function\": null,\n    \"framework\": \"torch\",\n    \"num_cpus_for_driver\": 1,\n    \"num_workers\": 7\n  },\n  \"evaluated_params\": {},\n  \"experiment_tag\": \"0\",\n  \"stopping_criterion\": {\n    \"timesteps_total\": 100000\n  },\n  \"_setup_default_resource\": true,\n  \"_default_placement_group_factory\": \"80054e2e\",\n  \"placement_group_factory\": \"8005950d010000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d948c0343505594473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff000000000000073658c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_default_result_or_future\": null,\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"relative_logdir\": \"SAC_politics_environment_20027_00000_0_2023-11-16_22-18-29\",\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"restore_path\": null,\n  \"_restore_checkpoint_result\": null,\n  \"_state_json\": null,\n  \"results\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_resources\": \"80054e2e\"\n}",
      "{\n  \"start_time\": 1700201925.700623,\n  \"num_failures\": 1,\n  \"num_failures_after_restore\": 0,\n  \"error_filename\": \"error.txt\",\n  \"pickled_error_filename\": \"error.pkl\",\n  \"last_result\": {\n    \"custom_metrics\": {},\n    \"episode_media\": {},\n    \"info\": {\n      \"learner\": {\n        \"agent_0\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 10.066781997680664,\n            \"actor_loss\": -4.2101945877075195,\n            \"critic_loss\": 4.579306602478027,\n            \"alpha_loss\": -0.02115008607506752,\n            \"alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430474767f3f94869452942e\"\n            },\n            \"log_alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048fb009bb94869452942e\"\n            },\n            \"target_entropy\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n            },\n            \"policy_t\": -0.004407154396176338,\n            \"mean_q\": 0.17144188284873962,\n            \"max_q\": 0.2639620304107666,\n            \"min_q\": 0.10190504789352417\n          },\n          \"td_error\": {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"800595c7010000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942842580100001eba8d40d455af40bca5d440183fa0405efab540536bc140a011974003719840b8398d400c7db640a6568f4045c3e640d97c913f580795407af2ca40ff266a3ee522ae40f164dc40bcbfe7400ef59040f6dad740e4b778400ba07f40a79bf040ee5ba840ce77b1405c4fab401cc6f04074edb54090978e408abe9f40aa90ae403b10e2401c1082401105e140608d054150548e3ee64754409266b0404e028140bc7f78408e24944018c4bd40f8429240ac54c940461b89409530d74098edf0400a0de340f65184409cd98e40d2308440621bf54054fd9640c4f3b740003cb740b1e299409851c9403fe4a8401c87b940e4920d410cd89540f8e2904068449140cab28040383693407e9b7a4076e45a403fb3e640fedad74092829e40bd2ec240c019ec40d0d08d4008c69740e623b5406c4ce8406a887b4024f4a7403e7c9740cd8390400cf7b8409210a7409c9beb409259ac402e1d7440948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b5685948c014394749452942e\"\n          },\n          \"mean_td_error\": 5.300106525421143,\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 86.0,\n          \"num_grad_updates_lifetime\": 8.0,\n          \"diff_num_grad_updates_vs_sampler_policy\": 7.0\n        },\n        \"agent_1\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 10.057534217834473,\n            \"actor_loss\": -4.20372200012207,\n            \"critic_loss\": 4.249048709869385,\n            \"alpha_loss\": -0.02112894505262375,\n            \"alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430477767f3f94869452942e\"\n            },\n            \"log_alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b4ad09bb94869452942e\"\n            },\n            \"target_entropy\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n            },\n            \"policy_t\": 0.023188062012195587,\n            \"mean_q\": 0.17906895279884338,\n            \"max_q\": 0.2811313271522522,\n            \"min_q\": 0.1167009100317955\n          },\n          \"td_error\": {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"800595c7010000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d62756666657294939428425801000038320441fbdb2141dce16340a4fffe3f047df94084f7ea402f7d90408eb813405c04de3f52865140ccf2ce406ac4b4404e9e0d41423620408fc19f40d4d5c74066241c41e71aba40d0772f40ee000841b18396409acaef40eeecc34094c4ce40c3d20e40f30b0141f89639401b32a840b90391404a3f42407bf24c408897d2404abaae40842e91402e168440939760402c0880405d63214192dfba402aab9940e0b815418a7a0b4101bdbc40ce96e0406ea32140956ff040267ef9401c01ec40b0c281406e0ecf4038adcd40aae97840fcd4064197b7084137024240d83b6a4086e17140011b3a401ab04440b88dc74064996e408bcfbe40f092804020a3b0405a0e854069608a407ca7ac40196a4d40b3e8ce402e513b4082c3c8409ccede409a80b4407fa1c54014d26940813894402b81534014117440f0e68440ea01a63e3ac866405a181241b06fc9408be6b640df0508415e4c1841948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b5685948c014394749452942e\"\n          },\n          \"mean_td_error\": 5.412673473358154,\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 86.0,\n          \"num_grad_updates_lifetime\": 8.0,\n          \"diff_num_grad_updates_vs_sampler_policy\": 7.0\n        },\n        \"agent_2\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 10.049541473388672,\n            \"actor_loss\": -4.192781448364258,\n            \"critic_loss\": 4.76000452041626,\n            \"alpha_loss\": -0.021109698340296745,\n            \"alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047b767f3f94869452942e\"\n            },\n            \"log_alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049aa909bb94869452942e\"\n            },\n            \"target_entropy\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n            },\n            \"policy_t\": 0.0014794436283409595,\n            \"mean_q\": 0.17932802438735962,\n            \"max_q\": 0.27653273940086365,\n            \"min_q\": 0.10767283290624619\n          },\n          \"td_error\": {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"800595c7010000000000008c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394284258010000cee07d40e520824010c8b4405107c4409dfec0403e2a9840b0c28f402cfa6b4015a38c40b4b0b840cb62d940e03d0e41579fcc402caf93402522ab40f848c94014adb740c2ab0341c31601419a2f2341e881ce40eef2e7401692ea404f69bf4042c38740ece495404431bf4059b18a40a20ddb40295c8f402aa7b840a85f9b40fe3b21407772d94032dde54036edf140f68d1b4177c10a4104a0a74063e58940b8c0ce406a3ff8406a84114086196240bef683403d8692406844184054833c40240ae540ba792940f40e9c402c314c408288cd4018b6e340d45e95409e1e9040f7fecb40195e9440861b9e402c4e3e40cefd6f404c6e77405b66c140a5560b41c2381c4197edcf40a69e004104b15b40041fce40368ab04048a9ae40de23ab40f7a8b440dd1cd240542f8d3f8a08564092d265407184854048806440e5eba940b915f03f7dfe8540d0bcb64074b6b8403541b040bb14e640948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624b5685948c014394749452942e\"\n          },\n          \"mean_td_error\": 5.461433410644531,\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 86.0,\n          \"num_grad_updates_lifetime\": 8.0,\n          \"diff_num_grad_updates_vs_sampler_policy\": 7.0\n        }\n      },\n      \"num_env_steps_sampled\": 8064,\n      \"num_env_steps_trained\": 2064,\n      \"num_agent_steps_sampled\": 24192,\n      \"num_agent_steps_trained\": 2064,\n      \"last_target_update_ts\": 8064,\n      \"num_target_updates\": 8\n    },\n    \"sampler_results\": {\n      \"episode_reward_max\": NaN,\n      \"episode_reward_min\": NaN,\n      \"episode_reward_mean\": NaN,\n      \"episode_len_mean\": NaN,\n      \"episode_media\": {},\n      \"episodes_this_iter\": 0,\n      \"policy_reward_min\": {},\n      \"policy_reward_max\": {},\n      \"policy_reward_mean\": {},\n      \"custom_metrics\": {},\n      \"hist_stats\": {\n        \"episode_reward\": [],\n        \"episode_lengths\": []\n      },\n      \"sampler_perf\": {},\n      \"num_faulty_episodes\": 0,\n      \"connector_metrics\": {}\n    },\n    \"episode_reward_max\": NaN,\n    \"episode_reward_min\": NaN,\n    \"episode_reward_mean\": NaN,\n    \"episode_len_mean\": NaN,\n    \"episodes_this_iter\": 0,\n    \"policy_reward_min\": {},\n    \"policy_reward_max\": {},\n    \"policy_reward_mean\": {},\n    \"hist_stats\": {\n      \"episode_reward\": [],\n      \"episode_lengths\": []\n    },\n    \"sampler_perf\": {},\n    \"num_faulty_episodes\": 0,\n    \"connector_metrics\": {},\n    \"num_healthy_workers\": 7,\n    \"num_in_flight_async_reqs\": 0,\n    \"num_remote_worker_restarts\": 0,\n    \"num_agent_steps_sampled\": 24192,\n    \"num_agent_steps_trained\": 2064,\n    \"num_env_steps_sampled\": 8064,\n    \"num_env_steps_trained\": 2064,\n    \"num_env_steps_sampled_this_iter\": 896,\n    \"num_env_steps_trained_this_iter\": 258,\n    \"num_env_steps_sampled_throughput_per_sec\": 479.0608587997322,\n    \"num_env_steps_trained_throughput_per_sec\": 137.9438633597443,\n    \"timesteps_total\": 8064,\n    \"num_steps_trained_this_iter\": 258,\n    \"agent_timesteps_total\": 24192,\n    \"timers\": {\n      \"training_iteration_time_ms\": 2084.623,\n      \"sample_time_ms\": 1351.794,\n      \"load_time_ms\": 0.527,\n      \"load_throughput\": 489651.779,\n      \"learn_time_ms\": 67.814,\n      \"learn_throughput\": 3804.54,\n      \"synch_weights_time_ms\": 17.465\n    },\n    \"counters\": {\n      \"num_env_steps_sampled\": 8064,\n      \"num_env_steps_trained\": 2064,\n      \"num_agent_steps_sampled\": 24192,\n      \"num_agent_steps_trained\": 2064,\n      \"last_target_update_ts\": 8064,\n      \"num_target_updates\": 8\n    },\n    \"done\": false,\n    \"episodes_total\": 0,\n    \"training_iteration\": 9,\n    \"trial_id\": \"20027_00000\",\n    \"date\": \"2023-11-16_22-19-04\",\n    \"timestamp\": 1700201944,\n    \"time_this_iter_s\": 1.8862597942352295,\n    \"time_total_s\": 18.888893365859985,\n    \"pid\": 48291,\n    \"hostname\": \"jang-yejun-ui-MacBookAir.local\",\n    \"node_ip\": \"127.0.0.1\",\n    \"config\": {\n      \"extra_python_environs_for_driver\": {},\n      \"extra_python_environs_for_worker\": {},\n      \"num_gpus\": 0,\n      \"num_cpus_per_worker\": 1,\n      \"num_gpus_per_worker\": 0,\n      \"_fake_gpus\": false,\n      \"num_learner_workers\": 0,\n      \"num_gpus_per_learner_worker\": 0,\n      \"num_cpus_per_learner_worker\": 1,\n      \"local_gpu_idx\": 0,\n      \"custom_resources_per_worker\": {},\n      \"placement_strategy\": \"PACK\",\n      \"eager_tracing\": true,\n      \"eager_max_retraces\": 20,\n      \"tf_session_args\": {\n        \"intra_op_parallelism_threads\": 2,\n        \"inter_op_parallelism_threads\": 2,\n        \"gpu_options\": {\n          \"allow_growth\": true\n        },\n        \"log_device_placement\": false,\n        \"device_count\": {\n          \"CPU\": 1\n        },\n        \"allow_soft_placement\": true\n      },\n      \"local_tf_session_args\": {\n        \"intra_op_parallelism_threads\": 8,\n        \"inter_op_parallelism_threads\": 8\n      },\n      \"torch_compile_learner\": false,\n      \"torch_compile_learner_what_to_compile\": \"forward_train\",\n      \"torch_compile_learner_dynamo_backend\": \"aot_eager\",\n      \"torch_compile_learner_dynamo_mode\": null,\n      \"torch_compile_worker\": false,\n      \"torch_compile_worker_dynamo_backend\": \"aot_eager\",\n      \"torch_compile_worker_dynamo_mode\": null,\n      \"env\": \"politics_environment\",\n      \"env_config\": {},\n      \"observation_space\": null,\n      \"action_space\": null,\n      \"env_task_fn\": null,\n      \"render_env\": false,\n      \"clip_rewards\": null,\n      \"normalize_actions\": true,\n      \"clip_actions\": true,\n      \"disable_env_checking\": false,\n      \"auto_wrap_old_gym_envs\": true,\n      \"action_mask_key\": \"action_mask\",\n      \"_is_atari\": null,\n      \"env_runner_cls\": null,\n      \"num_envs_per_worker\": 1,\n      \"sample_collector\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n      },\n      \"sample_async\": false,\n      \"enable_connectors\": true,\n      \"update_worker_filter_stats\": true,\n      \"use_worker_filter_stats\": true,\n      \"rollout_fragment_length\": 128,\n      \"batch_mode\": \"truncate_episodes\",\n      \"remote_worker_envs\": false,\n      \"remote_env_batch_wait_ms\": 0,\n      \"validate_workers_after_construction\": true,\n      \"preprocessor_pref\": \"deepmind\",\n      \"observation_filter\": \"NoFilter\",\n      \"compress_observations\": false,\n      \"enable_tf1_exec_eagerly\": false,\n      \"sampler_perf_stats_ema_coef\": null,\n      \"gamma\": 0.9,\n      \"lr\": 0.01,\n      \"grad_clip\": null,\n      \"grad_clip_by\": \"global_norm\",\n      \"train_batch_size\": 256,\n      \"model\": {\n        \"_disable_preprocessor_api\": false,\n        \"_disable_action_flattening\": false,\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"tanh\",\n        \"conv_filters\": null,\n        \"conv_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": \"relu\",\n        \"free_log_std\": false,\n        \"no_final_linear\": false,\n        \"vf_share_layers\": true,\n        \"use_lstm\": false,\n        \"max_seq_len\": 20,\n        \"lstm_cell_size\": 256,\n        \"lstm_use_prev_action\": false,\n        \"lstm_use_prev_reward\": false,\n        \"_time_major\": false,\n        \"use_attention\": false,\n        \"attention_num_transformer_units\": 1,\n        \"attention_dim\": 64,\n        \"attention_num_heads\": 1,\n        \"attention_head_dim\": 32,\n        \"attention_memory_inference\": 50,\n        \"attention_memory_training\": 50,\n        \"attention_position_wise_mlp_dim\": 32,\n        \"attention_init_gru_gate_bias\": 2.0,\n        \"attention_use_n_prev_actions\": 0,\n        \"attention_use_n_prev_rewards\": 0,\n        \"framestack\": true,\n        \"dim\": 84,\n        \"grayscale\": false,\n        \"zero_mean\": true,\n        \"custom_model\": null,\n        \"custom_model_config\": {},\n        \"custom_action_dist\": null,\n        \"custom_preprocessor\": null,\n        \"encoder_latent_dim\": null,\n        \"always_check_shapes\": false,\n        \"lstm_use_prev_action_reward\": -1,\n        \"_use_default_native_models\": -1\n      },\n      \"optimizer\": {},\n      \"max_requests_in_flight_per_sampler_worker\": 2,\n      \"_learner_class\": null,\n      \"_enable_learner_api\": false,\n      \"explore\": true,\n      \"exploration_config\": {\n        \"type\": \"StochasticSampling\"\n      },\n      \"algorithm_config_overrides_per_module\": {},\n      \"policy_map_capacity\": 100,\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0e5f6d616b655f66756e6374696f6e9493942868008c0d5f6275696c74696e5f747970659493948c08436f6465547970659485945294284b014b004b004b034b014b4f43047c005300944e8594298c086167656e745f6964948c0461726773948c066b77617267739487948c692f55736572732f6a616e672d79656a756e2f50726f6a656374732f5653436f646550726f6a656374732f534f554c5f70726f6a6563742f536f757263652f524c6c696250726163746963652f524c6c696270726163746963655f706f6c69746963735f656e762e7079948c083c6c616d6264613e944b2f4300942929749452947d94288c0b5f5f7061636b6167655f5f944e8c085f5f6e616d655f5f948c085f5f6d61696e5f5f948c085f5f66696c655f5f94680e754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f736574737461746594939468197d947d94286815680f8c0c5f5f7175616c6e616d655f5f94680f8c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f9468168c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n      },\n      \"policies_to_train\": null,\n      \"policy_states_are_swappable\": false,\n      \"observation_fn\": null,\n      \"count_steps_by\": \"env_steps\",\n      \"input_config\": {},\n      \"actions_in_input_normalized\": false,\n      \"postprocess_inputs\": false,\n      \"shuffle_buffer_size\": 0,\n      \"output\": null,\n      \"output_config\": {},\n      \"output_compress_columns\": [\n        \"obs\",\n        \"new_obs\"\n      ],\n      \"output_max_file_size\": 67108864,\n      \"offline_sampling\": false,\n      \"evaluation_interval\": null,\n      \"evaluation_duration\": 10,\n      \"evaluation_duration_unit\": \"episodes\",\n      \"evaluation_sample_timeout_s\": 180.0,\n      \"evaluation_parallel_to_training\": false,\n      \"evaluation_config\": null,\n      \"off_policy_estimation_methods\": {},\n      \"ope_split_batch_by_episode\": true,\n      \"evaluation_num_workers\": 0,\n      \"always_attach_evaluation_results\": false,\n      \"enable_async_evaluation\": false,\n      \"in_evaluation\": false,\n      \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n      \"keep_per_episode_custom_metrics\": false,\n      \"metrics_episode_collection_timeout_s\": 60.0,\n      \"metrics_num_episodes_for_smoothing\": 100,\n      \"min_time_s_per_iteration\": 1,\n      \"min_train_timesteps_per_iteration\": 0,\n      \"min_sample_timesteps_per_iteration\": 100,\n      \"export_native_model_files\": false,\n      \"checkpoint_trainable_policies_only\": false,\n      \"logger_creator\": null,\n      \"logger_config\": null,\n      \"log_level\": \"ERROR\",\n      \"log_sys_usage\": true,\n      \"fake_sampler\": false,\n      \"seed\": null,\n      \"ignore_worker_failures\": false,\n      \"recreate_failed_workers\": false,\n      \"max_num_worker_restarts\": 1000,\n      \"delay_between_worker_restarts_s\": 60.0,\n      \"restart_failed_sub_environments\": false,\n      \"num_consecutive_worker_failures_tolerance\": 100,\n      \"worker_health_probe_timeout_s\": 60,\n      \"worker_restore_timeout_s\": 1800,\n      \"rl_module_spec\": null,\n      \"_enable_rl_module_api\": false,\n      \"_AlgorithmConfig__prior_exploration_config\": null,\n      \"_tf_policy_handles_more_than_one_loss\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"_disable_execution_plan_api\": true,\n      \"_disable_initialize_loss_from_dummy_batch\": false,\n      \"simple_optimizer\": false,\n      \"policy_map_cache\": -1,\n      \"worker_cls\": -1,\n      \"synchronize_filters\": -1,\n      \"replay_sequence_length\": null,\n      \"twin_q\": true,\n      \"q_model_config\": {\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": null,\n        \"custom_model\": null,\n        \"custom_model_config\": {}\n      },\n      \"policy_model_config\": {\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": null,\n        \"custom_model\": null,\n        \"custom_model_config\": {}\n      },\n      \"tau\": 0.005,\n      \"initial_alpha\": 1.0,\n      \"target_entropy\": \"auto\",\n      \"n_step\": 1,\n      \"replay_buffer_config\": {\n        \"_enable_replay_buffer_api\": true,\n        \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n        \"capacity\": 1000000,\n        \"prioritized_replay\": false,\n        \"prioritized_replay_alpha\": 0.6,\n        \"prioritized_replay_beta\": 0.4,\n        \"prioritized_replay_eps\": 1e-06,\n        \"worker_side_prioritization\": false\n      },\n      \"store_buffer_in_checkpoints\": false,\n      \"training_intensity\": null,\n      \"optimization\": {\n        \"actor_learning_rate\": 0.0003,\n        \"critic_learning_rate\": 0.0003,\n        \"entropy_learning_rate\": 0.0003\n      },\n      \"target_network_update_freq\": 0,\n      \"num_steps_sampled_before_learning_starts\": 1500,\n      \"_deterministic_loss\": false,\n      \"_use_beta_distribution\": false,\n      \"use_state_preprocessor\": -1,\n      \"worker_side_prioritization\": -1,\n      \"__stdout_file__\": null,\n      \"__stderr_file__\": null,\n      \"input\": \"sampler\",\n      \"policies\": {\n        \"agent_0\": [\n          null,\n          {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"800595d8010000000000008c1467796d6e617369756d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994680593948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0d626f756e6465645f62656c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843090101010101010101019468078c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b0985948c014394749452948c0d626f756e6465645f61626f76659468102843090101010101010101019468144b0985946818749452948c065f7368617065944b0985948c036c6f779468102843240000000000000000000000000000000000000000000000000000000000000000000000009468078c02663494898887945294284b03680b4e4e4e4affffffff4affffffff4b007494624b0985946818749452948c04686967689468102843240000004000000040000000400000004000000040000000400000004000000040000000409468264b0985946818749452948c086c6f775f72657072948c03302e30948c09686967685f72657072948c03322e30948c0a5f6e705f72616e646f6d944e75622e\"\n          },\n          {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"800595bb010000000000008c1467796d6e617369756d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994680593948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0d626f756e6465645f62656c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843060000000000009468078c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b0685948c014394749452948c0d626f756e6465645f61626f76659468102843060000000000009468144b0685946818749452948c065f7368617065944b0685948c036c6f77946810284318000080ff000080ff000080ff000080ff000080ff000080ff9468078c02663494898887945294284b03680b4e4e4e4affffffff4affffffff4b007494624b0685946818749452948c04686967689468102843180000807f0000807f0000807f0000807f0000807f0000807f9468264b0685946818749452948c086c6f775f72657072948c042d696e66948c09686967685f72657072948c03696e66948c0a5f6e705f72616e646f6d944e75622e\"\n          },\n          {}\n        ],\n        \"agent_1\": [\n          null,\n          {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"800595d8010000000000008c1467796d6e617369756d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994680593948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0d626f756e6465645f62656c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843090101010101010101019468078c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b0985948c014394749452948c0d626f756e6465645f61626f76659468102843090101010101010101019468144b0985946818749452948c065f7368617065944b0985948c036c6f779468102843240000000000000000000000000000000000000000000000000000000000000000000000009468078c02663494898887945294284b03680b4e4e4e4affffffff4affffffff4b007494624b0985946818749452948c04686967689468102843240000004000000040000000400000004000000040000000400000004000000040000000409468264b0985946818749452948c086c6f775f72657072948c03302e30948c09686967685f72657072948c03322e30948c0a5f6e705f72616e646f6d944e75622e\"\n          },\n          {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"800595bb010000000000008c1467796d6e617369756d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994680593948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0d626f756e6465645f62656c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843060000000000009468078c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b0685948c014394749452948c0d626f756e6465645f61626f76659468102843060000000000009468144b0685946818749452948c065f7368617065944b0685948c036c6f77946810284318000080ff000080ff000080ff000080ff000080ff000080ff9468078c02663494898887945294284b03680b4e4e4e4affffffff4affffffff4b007494624b0685946818749452948c04686967689468102843180000807f0000807f0000807f0000807f0000807f0000807f9468264b0685946818749452948c086c6f775f72657072948c042d696e66948c09686967685f72657072948c03696e66948c0a5f6e705f72616e646f6d944e75622e\"\n          },\n          {}\n        ],\n        \"agent_2\": [\n          null,\n          {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"800595d8010000000000008c1467796d6e617369756d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994680593948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0d626f756e6465645f62656c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843090101010101010101019468078c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b0985948c014394749452948c0d626f756e6465645f61626f76659468102843090101010101010101019468144b0985946818749452948c065f7368617065944b0985948c036c6f779468102843240000000000000000000000000000000000000000000000000000000000000000000000009468078c02663494898887945294284b03680b4e4e4e4affffffff4affffffff4b007494624b0985946818749452948c04686967689468102843240000004000000040000000400000004000000040000000400000004000000040000000409468264b0985946818749452948c086c6f775f72657072948c03302e30948c09686967685f72657072948c03322e30948c0a5f6e705f72616e646f6d944e75622e\"\n          },\n          {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"800595bb010000000000008c1467796d6e617369756d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994680593948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0d626f756e6465645f62656c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d6275666665729493942843060000000000009468078c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b0685948c014394749452948c0d626f756e6465645f61626f76659468102843060000000000009468144b0685946818749452948c065f7368617065944b0685948c036c6f77946810284318000080ff000080ff000080ff000080ff000080ff000080ff9468078c02663494898887945294284b03680b4e4e4e4affffffff4affffffff4b007494624b0685946818749452948c04686967689468102843180000807f0000807f0000807f0000807f0000807f0000807f9468264b0685946818749452948c086c6f775f72657072948c042d696e66948c09686967685f72657072948c03696e66948c0a5f6e705f72616e646f6d944e75622e\"\n          },\n          {}\n        ]\n      },\n      \"callbacks\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059537000000000000008c1e7261792e726c6c69622e616c676f726974686d732e63616c6c6261636b73948c1044656661756c7443616c6c6261636b739493942e\"\n      },\n      \"create_env_on_driver\": false,\n      \"custom_eval_function\": null,\n      \"framework\": \"torch\",\n      \"num_cpus_for_driver\": 1,\n      \"num_workers\": 7\n    },\n    \"time_since_restore\": 18.888893365859985,\n    \"iterations_since_restore\": 9,\n    \"perf\": {\n      \"cpu_util_percent\": 85.75,\n      \"ram_util_percent\": 92.2\n    },\n    \"experiment_tag\": \"0\"\n  },\n  \"last_result_time\": 1700201944.851636,\n  \"metric_analysis\": {\n    \"episode_reward_max\": {\n      \"max\": NaN,\n      \"min\": NaN,\n      \"avg\": NaN,\n      \"last\": NaN,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"episode_reward_min\": {\n      \"max\": NaN,\n      \"min\": NaN,\n      \"avg\": NaN,\n      \"last\": NaN,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"episode_reward_mean\": {\n      \"max\": NaN,\n      \"min\": NaN,\n      \"avg\": NaN,\n      \"last\": NaN,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"episode_len_mean\": {\n      \"max\": NaN,\n      \"min\": NaN,\n      \"avg\": NaN,\n      \"last\": NaN,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"episodes_this_iter\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_healthy_workers\": {\n      \"max\": 7,\n      \"min\": 7,\n      \"avg\": 7.0,\n      \"last\": 7,\n      \"last-5-avg\": 7.0,\n      \"last-10-avg\": 7.0\n    },\n    \"num_in_flight_async_reqs\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_remote_worker_restarts\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_agent_steps_sampled\": {\n      \"max\": 24192,\n      \"min\": 2688,\n      \"avg\": 13440.0,\n      \"last\": 24192,\n      \"last-5-avg\": 18816.0,\n      \"last-10-avg\": 13440.0\n    },\n    \"num_agent_steps_trained\": {\n      \"max\": 2064,\n      \"min\": 0,\n      \"avg\": 1032.0,\n      \"last\": 2064,\n      \"last-5-avg\": 1548.0,\n      \"last-10-avg\": 1032.0\n    },\n    \"num_env_steps_sampled\": {\n      \"max\": 8064,\n      \"min\": 896,\n      \"avg\": 4480.0,\n      \"last\": 8064,\n      \"last-5-avg\": 6272.0,\n      \"last-10-avg\": 4480.0\n    },\n    \"num_env_steps_trained\": {\n      \"max\": 2064,\n      \"min\": 0,\n      \"avg\": 1032.0,\n      \"last\": 2064,\n      \"last-5-avg\": 1548.0,\n      \"last-10-avg\": 1032.0\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"max\": 896,\n      \"min\": 896,\n      \"avg\": 896.0,\n      \"last\": 896,\n      \"last-5-avg\": 896.0,\n      \"last-10-avg\": 896.0\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"max\": 258,\n      \"min\": 0,\n      \"avg\": 229.33333333333331,\n      \"last\": 258,\n      \"last-5-avg\": 258.0,\n      \"last-10-avg\": 229.33333333333334\n    },\n    \"num_env_steps_sampled_throughput_per_sec\": {\n      \"max\": 494.578188661079,\n      \"min\": 293.53470724569263,\n      \"avg\": 441.28182046398086,\n      \"last\": 479.0608587997322,\n      \"last-5-avg\": 469.15772087489995,\n      \"last-10-avg\": 441.2818204639809\n    },\n    \"num_env_steps_trained_throughput_per_sec\": {\n      \"max\": 142.41202307428392,\n      \"min\": 0.0,\n      \"avg\": 117.67416079463975,\n      \"last\": 137.9438633597443,\n      \"last-5-avg\": 135.0922901626386,\n      \"last-10-avg\": 117.67416079463975\n    },\n    \"timesteps_total\": {\n      \"max\": 8064,\n      \"min\": 896,\n      \"avg\": 4480.0,\n      \"last\": 8064,\n      \"last-5-avg\": 6272.0,\n      \"last-10-avg\": 4480.0\n    },\n    \"num_steps_trained_this_iter\": {\n      \"max\": 258,\n      \"min\": 0,\n      \"avg\": 229.33333333333331,\n      \"last\": 258,\n      \"last-5-avg\": 258.0,\n      \"last-10-avg\": 229.33333333333334\n    },\n    \"agent_timesteps_total\": {\n      \"max\": 24192,\n      \"min\": 2688,\n      \"avg\": 13440.0,\n      \"last\": 24192,\n      \"last-5-avg\": 18816.0,\n      \"last-10-avg\": 13440.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"episodes_total\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"training_iteration\": {\n      \"max\": 9,\n      \"min\": 1,\n      \"avg\": 5.0,\n      \"last\": 9,\n      \"last-5-avg\": 7.0,\n      \"last-10-avg\": 5.0\n    },\n    \"time_this_iter_s\": {\n      \"max\": 3.056164026260376,\n      \"min\": 1.827847957611084,\n      \"avg\": 2.098765929539998,\n      \"last\": 1.8862597942352295,\n      \"last-5-avg\": 1.9285865306854248,\n      \"last-10-avg\": 2.0987659295399985\n    },\n    \"time_total_s\": {\n      \"max\": 18.888893365859985,\n      \"min\": 3.056164026260376,\n      \"avg\": 11.147106568018593,\n      \"last\": 18.888893365859985,\n      \"last-5-avg\": 15.051688957214356,\n      \"last-10-avg\": 11.147106568018595\n    },\n    \"time_since_restore\": {\n      \"max\": 18.888893365859985,\n      \"min\": 3.056164026260376,\n      \"avg\": 11.147106568018593,\n      \"last\": 18.888893365859985,\n      \"last-5-avg\": 15.051688957214356,\n      \"last-10-avg\": 11.147106568018595\n    },\n    \"iterations_since_restore\": {\n      \"max\": 9,\n      \"min\": 1,\n      \"avg\": 5.0,\n      \"last\": 9,\n      \"last-5-avg\": 7.0,\n      \"last-10-avg\": 5.0\n    },\n    \"info/num_env_steps_sampled\": {\n      \"max\": 8064,\n      \"min\": 896,\n      \"avg\": 4480.0,\n      \"last\": 8064,\n      \"last-5-avg\": 6272.0,\n      \"last-10-avg\": 4480.0\n    },\n    \"info/num_env_steps_trained\": {\n      \"max\": 2064,\n      \"min\": 0,\n      \"avg\": 1032.0,\n      \"last\": 2064,\n      \"last-5-avg\": 1548.0,\n      \"last-10-avg\": 1032.0\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"max\": 24192,\n      \"min\": 2688,\n      \"avg\": 13440.0,\n      \"last\": 24192,\n      \"last-5-avg\": 18816.0,\n      \"last-10-avg\": 13440.0\n    },\n    \"info/num_agent_steps_trained\": {\n      \"max\": 2064,\n      \"min\": 0,\n      \"avg\": 1032.0,\n      \"last\": 2064,\n      \"last-5-avg\": 1548.0,\n      \"last-10-avg\": 1032.0\n    },\n    \"sampler_results/episode_reward_max\": {\n      \"max\": NaN,\n      \"min\": NaN,\n      \"avg\": NaN,\n      \"last\": NaN,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"sampler_results/episode_reward_min\": {\n      \"max\": NaN,\n      \"min\": NaN,\n      \"avg\": NaN,\n      \"last\": NaN,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"sampler_results/episode_reward_mean\": {\n      \"max\": NaN,\n      \"min\": NaN,\n      \"avg\": NaN,\n      \"last\": NaN,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"sampler_results/episode_len_mean\": {\n      \"max\": NaN,\n      \"min\": NaN,\n      \"avg\": NaN,\n      \"last\": NaN,\n      \"last-5-avg\": NaN,\n      \"last-10-avg\": NaN\n    },\n    \"sampler_results/episodes_this_iter\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_results/num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"max\": 3052.402,\n      \"min\": 2084.623,\n      \"avg\": 2357.8317777777775,\n      \"last\": 2084.623,\n      \"last-5-avg\": 2145.264,\n      \"last-10-avg\": 2357.831777777778\n    },\n    \"timers/sample_time_ms\": {\n      \"max\": 1545.156,\n      \"min\": 1351.794,\n      \"avg\": 1417.0514444444443,\n      \"last\": 1351.794,\n      \"last-5-avg\": 1367.6852000000001,\n      \"last-10-avg\": 1417.0514444444443\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"max\": 8064,\n      \"min\": 896,\n      \"avg\": 4480.0,\n      \"last\": 8064,\n      \"last-5-avg\": 6272.0,\n      \"last-10-avg\": 4480.0\n    },\n    \"counters/num_env_steps_trained\": {\n      \"max\": 2064,\n      \"min\": 0,\n      \"avg\": 1032.0,\n      \"last\": 2064,\n      \"last-5-avg\": 1548.0,\n      \"last-10-avg\": 1032.0\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"max\": 24192,\n      \"min\": 2688,\n      \"avg\": 13440.0,\n      \"last\": 24192,\n      \"last-5-avg\": 18816.0,\n      \"last-10-avg\": 13440.0\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"max\": 2064,\n      \"min\": 0,\n      \"avg\": 1032.0,\n      \"last\": 2064,\n      \"last-5-avg\": 1548.0,\n      \"last-10-avg\": 1032.0\n    },\n    \"perf/cpu_util_percent\": {\n      \"max\": 85.75,\n      \"min\": 47.36,\n      \"avg\": 68.12148148148147,\n      \"last\": 85.75,\n      \"last-5-avg\": 73.13333333333333,\n      \"last-10-avg\": 68.12148148148148\n    },\n    \"perf/ram_util_percent\": {\n      \"max\": 92.2,\n      \"min\": 91.97999999999999,\n      \"avg\": 92.09777777777778,\n      \"last\": 92.2,\n      \"last-5-avg\": 92.13333333333333,\n      \"last-10-avg\": 92.09777777777778\n    },\n    \"info/last_target_update_ts\": {\n      \"max\": 8064,\n      \"min\": 1792,\n      \"avg\": 4579.555555555556,\n      \"last\": 8064,\n      \"last-5-avg\": 6272.0,\n      \"last-10-avg\": 4928.0\n    },\n    \"info/num_target_updates\": {\n      \"max\": 8,\n      \"min\": 1,\n      \"avg\": 4.111111111111111,\n      \"last\": 8,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    },\n    \"timers/load_time_ms\": {\n      \"max\": 0.534,\n      \"min\": 0.522,\n      \"avg\": 0.5273333333333332,\n      \"last\": 0.527,\n      \"last-5-avg\": 0.5266000000000001,\n      \"last-10-avg\": 0.5265\n    },\n    \"timers/load_throughput\": {\n      \"max\": 493897.961,\n      \"min\": 483093.943,\n      \"avg\": 489228.0743333333,\n      \"last\": 489651.779,\n      \"last-5-avg\": 489858.836,\n      \"last-10-avg\": 489994.84075000003\n    },\n    \"timers/learn_time_ms\": {\n      \"max\": 93.521,\n      \"min\": 67.814,\n      \"avg\": 76.65011111111109,\n      \"last\": 67.814,\n      \"last-5-avg\": 69.61200000000001,\n      \"last-10-avg\": 74.54124999999999\n    },\n    \"timers/learn_throughput\": {\n      \"max\": 3804.54,\n      \"min\": 2758.742,\n      \"avg\": 3414.793333333333,\n      \"last\": 3804.54,\n      \"last-5-avg\": 3707.8292,\n      \"last-10-avg\": 3496.79975\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"max\": 17.836,\n      \"min\": 15.791,\n      \"avg\": 16.984,\n      \"last\": 17.465,\n      \"last-5-avg\": 17.3578,\n      \"last-10-avg\": 17.133125\n    },\n    \"counters/last_target_update_ts\": {\n      \"max\": 8064,\n      \"min\": 1792,\n      \"avg\": 4579.555555555556,\n      \"last\": 8064,\n      \"last-5-avg\": 6272.0,\n      \"last-10-avg\": 4928.0\n    },\n    \"counters/num_target_updates\": {\n      \"max\": 8,\n      \"min\": 1,\n      \"avg\": 4.111111111111111,\n      \"last\": 8,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    },\n    \"info/learner/agent_0/mean_td_error\": {\n      \"max\": 5.819341659545898,\n      \"min\": 5.300106525421143,\n      \"avg\": 5.580255826314289,\n      \"last\": 5.300106525421143,\n      \"last-5-avg\": 5.583329772949218,\n      \"last-10-avg\": 5.5866639614105225\n    },\n    \"info/learner/agent_0/num_agent_steps_trained\": {\n      \"max\": 86.0,\n      \"min\": 86.0,\n      \"avg\": 86.0,\n      \"last\": 86.0,\n      \"last-5-avg\": 86.0,\n      \"last-10-avg\": 86.0\n    },\n    \"info/learner/agent_0/num_grad_updates_lifetime\": {\n      \"max\": 8.0,\n      \"min\": 1.0,\n      \"avg\": 4.111111111111111,\n      \"last\": 8.0,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    },\n    \"info/learner/agent_0/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 7.0,\n      \"min\": 0.0,\n      \"avg\": 3.1111111111111107,\n      \"last\": 7.0,\n      \"last-5-avg\": 5.0,\n      \"last-10-avg\": 3.5\n    },\n    \"info/learner/agent_1/mean_td_error\": {\n      \"max\": 5.514244079589844,\n      \"min\": 3.9645843505859375,\n      \"avg\": 4.745605574713813,\n      \"last\": 5.412673473358154,\n      \"last-5-avg\": 5.2137706756591795,\n      \"last-10-avg\": 4.843233227729797\n    },\n    \"info/learner/agent_1/num_agent_steps_trained\": {\n      \"max\": 86.0,\n      \"min\": 86.0,\n      \"avg\": 86.0,\n      \"last\": 86.0,\n      \"last-5-avg\": 86.0,\n      \"last-10-avg\": 86.0\n    },\n    \"info/learner/agent_1/num_grad_updates_lifetime\": {\n      \"max\": 8.0,\n      \"min\": 1.0,\n      \"avg\": 4.111111111111111,\n      \"last\": 8.0,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    },\n    \"info/learner/agent_1/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 7.0,\n      \"min\": 0.0,\n      \"avg\": 3.1111111111111107,\n      \"last\": 7.0,\n      \"last-5-avg\": 5.0,\n      \"last-10-avg\": 3.5\n    },\n    \"info/learner/agent_2/mean_td_error\": {\n      \"max\": 5.461433410644531,\n      \"min\": 4.257933139801025,\n      \"avg\": 4.76471741994222,\n      \"last\": 5.461433410644531,\n      \"last-5-avg\": 5.0607301712036135,\n      \"last-10-avg\": 4.828058421611786\n    },\n    \"info/learner/agent_2/num_agent_steps_trained\": {\n      \"max\": 86.0,\n      \"min\": 86.0,\n      \"avg\": 86.0,\n      \"last\": 86.0,\n      \"last-5-avg\": 86.0,\n      \"last-10-avg\": 86.0\n    },\n    \"info/learner/agent_2/num_grad_updates_lifetime\": {\n      \"max\": 8.0,\n      \"min\": 1.0,\n      \"avg\": 4.111111111111111,\n      \"last\": 8.0,\n      \"last-5-avg\": 6.0,\n      \"last-10-avg\": 4.5\n    },\n    \"info/learner/agent_2/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 7.0,\n      \"min\": 0.0,\n      \"avg\": 3.1111111111111107,\n      \"last\": 7.0,\n      \"last-5-avg\": 5.0,\n      \"last-10-avg\": 3.5\n    },\n    \"info/learner/agent_0/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_0/learner_stats/grad_gnorm\": {\n      \"max\": 10.135682106018066,\n      \"min\": 9.919191360473633,\n      \"avg\": 10.051675266689724,\n      \"last\": 10.066781997680664,\n      \"last-5-avg\": 10.093520736694336,\n      \"last-10-avg\": 10.068235754966736\n    },\n    \"info/learner/agent_0/learner_stats/actor_loss\": {\n      \"max\": -3.918323516845703,\n      \"min\": -4.245088577270508,\n      \"avg\": -4.104254563649495,\n      \"last\": -4.2101945877075195,\n      \"last-5-avg\": -4.181023406982422,\n      \"last-10-avg\": -4.1274959444999695\n    },\n    \"info/learner/agent_0/learner_stats/critic_loss\": {\n      \"max\": 5.045336723327637,\n      \"min\": 4.48936653137207,\n      \"avg\": 4.875125302208795,\n      \"last\": 4.579306602478027,\n      \"last-5-avg\": 4.778593826293945,\n      \"last-10-avg\": 4.855890929698944\n    },\n    \"info/learner/agent_0/learner_stats/alpha_loss\": {\n      \"max\": 0.0,\n      \"min\": -0.02115008607506752,\n      \"avg\": -0.009420507121831179,\n      \"last\": -0.02115008607506752,\n      \"last-5-avg\": -0.015145455300807954,\n      \"last-10-avg\": -0.010598070512060076\n    },\n    \"info/learner/agent_0/learner_stats/alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430474767f3f94869452942e\"\n      },\n      \"avg\": 0.9990670283635457,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430474767f3f94869452942e\"\n      },\n      \"last-5-avg\": 0.9985006332397461,\n      \"last-10-avg\": 0.998950406908989\n    },\n    \"info/learner/agent_0/learner_stats/log_alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048fb009bb94869452942e\"\n      },\n      \"avg\": -0.0009336733071702635,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048fb009bb94869452942e\"\n      },\n      \"last-5-avg\": -0.0015005821245722474,\n      \"last-10-avg\": -0.0010503824705665465\n    },\n    \"info/learner/agent_0/learner_stats/target_entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"avg\": -6.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"last-5-avg\": -6.0,\n      \"last-10-avg\": -6.0\n    },\n    \"info/learner/agent_0/learner_stats/policy_t\": {\n      \"max\": 0.04840852692723274,\n      \"min\": -0.03121023438870907,\n      \"avg\": 0.0005230892242656821,\n      \"last\": -0.004407154396176338,\n      \"last-5-avg\": -0.0123525969684124,\n      \"last-10-avg\": -0.0012335178907960653\n    },\n    \"info/learner/agent_0/learner_stats/mean_q\": {\n      \"max\": 0.17144188284873962,\n      \"min\": 0.0007435117149725556,\n      \"avg\": 0.06410303041856322,\n      \"last\": 0.17144188284873962,\n      \"last-5-avg\": 0.1057991310954094,\n      \"last-10-avg\": 0.07202297025651205\n    },\n    \"info/learner/agent_0/learner_stats/max_q\": {\n      \"max\": 0.2639620304107666,\n      \"min\": 0.005679157562553883,\n      \"avg\": 0.09686979403098424,\n      \"last\": 0.2639620304107666,\n      \"last-5-avg\": 0.16006911993026735,\n      \"last-10-avg\": 0.10826862358953804\n    },\n    \"info/learner/agent_0/learner_stats/min_q\": {\n      \"max\": 0.10190504789352417,\n      \"min\": -0.004440023098140955,\n      \"avg\": 0.04185910978251033,\n      \"last\": 0.10190504789352417,\n      \"last-5-avg\": 0.0703146830201149,\n      \"last-10-avg\": 0.047646501392591745\n    },\n    \"info/learner/agent_1/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_1/learner_stats/grad_gnorm\": {\n      \"max\": 10.12377643585205,\n      \"min\": 9.931831359863281,\n      \"avg\": 10.034786224365234,\n      \"last\": 10.057534217834473,\n      \"last-5-avg\": 10.057677268981934,\n      \"last-10-avg\": 10.047655582427979\n    },\n    \"info/learner/agent_1/learner_stats/actor_loss\": {\n      \"max\": -3.925860643386841,\n      \"min\": -4.238536357879639,\n      \"avg\": -4.087305492824977,\n      \"last\": -4.20372200012207,\n      \"last-5-avg\": -4.148659706115723,\n      \"last-10-avg\": -4.1074860990047455\n    },\n    \"info/learner/agent_1/learner_stats/critic_loss\": {\n      \"max\": 4.298274993896484,\n      \"min\": 3.4645845890045166,\n      \"avg\": 3.9051682419247093,\n      \"last\": 4.249048709869385,\n      \"last-5-avg\": 4.126501512527466,\n      \"last-10-avg\": 3.960241198539734\n    },\n    \"info/learner/agent_1/learner_stats/alpha_loss\": {\n      \"max\": 0.0,\n      \"min\": -0.02112894505262375,\n      \"avg\": -0.009399143487422002,\n      \"last\": -0.02112894505262375,\n      \"last-5-avg\": -0.01510121151804924,\n      \"last-10-avg\": -0.010574036423349753\n    },\n    \"info/learner/agent_1/learner_stats/alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430477767f3f94869452942e\"\n      },\n      \"avg\": 0.9990670747227138,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430477767f3f94869452942e\"\n      },\n      \"last-5-avg\": 0.9985007047653198,\n      \"last-10-avg\": 0.9989504590630531\n    },\n    \"info/learner/agent_1/learner_stats/log_alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b4ad09bb94869452942e\"\n      },\n      \"avg\": -0.0009336256836023595,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b4ad09bb94869452942e\"\n      },\n      \"last-5-avg\": -0.0015005105640739202,\n      \"last-10-avg\": -0.0010503288940526545\n    },\n    \"info/learner/agent_1/learner_stats/target_entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"avg\": -6.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"last-5-avg\": -6.0,\n      \"last-10-avg\": -6.0\n    },\n    \"info/learner/agent_1/learner_stats/policy_t\": {\n      \"max\": 0.023188062012195587,\n      \"min\": -0.05814886465668678,\n      \"avg\": -0.0037086349911987764,\n      \"last\": 0.023188062012195587,\n      \"last-5-avg\": -0.002628810703754425,\n      \"last-10-avg\": -0.003696164087159559\n    },\n    \"info/learner/agent_1/learner_stats/mean_q\": {\n      \"max\": 0.17906895279884338,\n      \"min\": 0.0018634245498105884,\n      \"avg\": 0.06993552708687881,\n      \"last\": 0.17906895279884338,\n      \"last-5-avg\": 0.11482031419873237,\n      \"last-10-avg\": 0.07844453990401234\n    },\n    \"info/learner/agent_1/learner_stats/max_q\": {\n      \"max\": 0.2811313271522522,\n      \"min\": 0.006325979251414537,\n      \"avg\": 0.1045345456028978,\n      \"last\": 0.2811313271522522,\n      \"last-5-avg\": 0.17140450924634934,\n      \"last-10-avg\": 0.11681061639683321\n    },\n    \"info/learner/agent_1/learner_stats/min_q\": {\n      \"max\": 0.1167009100317955,\n      \"min\": -0.0026662610471248627,\n      \"avg\": 0.04596181586384773,\n      \"last\": 0.1167009100317955,\n      \"last-5-avg\": 0.07624491974711418,\n      \"last-10-avg\": 0.05204032547771931\n    },\n    \"info/learner/agent_2/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/agent_2/learner_stats/grad_gnorm\": {\n      \"max\": 10.099010467529297,\n      \"min\": 9.964287757873535,\n      \"avg\": 10.034061537848578,\n      \"last\": 10.049541473388672,\n      \"last-5-avg\": 10.04822826385498,\n      \"last-10-avg\": 10.042783260345459\n    },\n    \"info/learner/agent_2/learner_stats/actor_loss\": {\n      \"max\": -3.965502977371216,\n      \"min\": -4.192781448364258,\n      \"avg\": -4.087882306840685,\n      \"last\": -4.192781448364258,\n      \"last-5-avg\": -4.136577224731445,\n      \"last-10-avg\": -4.103179723024368\n    },\n    \"info/learner/agent_2/learner_stats/critic_loss\": {\n      \"max\": 4.76000452041626,\n      \"min\": 3.7266106605529785,\n      \"avg\": 4.149031321207682,\n      \"last\": 4.76000452041626,\n      \"last-5-avg\": 4.387948322296142,\n      \"last-10-avg\": 4.197911590337753\n    },\n    \"info/learner/agent_2/learner_stats/alpha_loss\": {\n      \"max\": 0.0,\n      \"min\": -0.021109698340296745,\n      \"avg\": -0.009384027190713419,\n      \"last\": -0.021109698340296745,\n      \"last-5-avg\": -0.015077216923236847,\n      \"last-10-avg\": -0.010557030589552596\n    },\n    \"info/learner/agent_2/learner_stats/alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047b767f3f94869452942e\"\n      },\n      \"avg\": 0.9990671475728352,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047b767f3f94869452942e\"\n      },\n      \"last-5-avg\": 0.9985008239746094,\n      \"last-10-avg\": 0.9989505410194397\n    },\n    \"info/learner/agent_2/learner_stats/log_alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000000094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049aa909bb94869452942e\"\n      },\n      \"avg\": -0.0009335531600906203,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049aa909bb94869452942e\"\n      },\n      \"last-5-avg\": -0.0015003840206190943,\n      \"last-10-avg\": -0.0010502473051019479\n    },\n    \"info/learner/agent_2/learner_stats/target_entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"avg\": -6.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"last-5-avg\": -6.0,\n      \"last-10-avg\": -6.0\n    },\n    \"info/learner/agent_2/learner_stats/policy_t\": {\n      \"max\": 0.04443054273724556,\n      \"min\": -0.03783313184976578,\n      \"avg\": 0.0021471316382909804,\n      \"last\": 0.0014794436283409595,\n      \"last-5-avg\": 0.009741410496644676,\n      \"last-10-avg\": 0.003997530133347027\n    },\n    \"info/learner/agent_2/learner_stats/mean_q\": {\n      \"max\": 0.17932802438735962,\n      \"min\": 0.005263937637209892,\n      \"avg\": 0.07099982909858227,\n      \"last\": 0.17932802438735962,\n      \"last-5-avg\": 0.11359162256121635,\n      \"last-10-avg\": 0.07921681553125381\n    },\n    \"info/learner/agent_2/learner_stats/max_q\": {\n      \"max\": 0.27653273940086365,\n      \"min\": 0.01057092472910881,\n      \"avg\": 0.10367532012363274,\n      \"last\": 0.27653273940086365,\n      \"last-5-avg\": 0.1671043172478676,\n      \"last-10-avg\": 0.11531336954794824\n    },\n    \"info/learner/agent_2/learner_stats/min_q\": {\n      \"max\": 0.10767283290624619,\n      \"min\": 0.0018562248442322016,\n      \"avg\": 0.04727916031455,\n      \"last\": 0.10767283290624619,\n      \"last-5-avg\": 0.07521419003605842,\n      \"last-10-avg\": 0.05295702724833973\n    }\n  },\n  \"_n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059573000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000652e\"\n      }\n    },\n    \"episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059573000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000652e\"\n      }\n    },\n    \"episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059573000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000652e\"\n      }\n    },\n    \"episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059573000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000652e\"\n      }\n    },\n    \"episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_healthy_workers\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b074b074b074b074b07652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b074b074b074b074b074b074b074b074b07652e\"\n      }\n    },\n    \"num_in_flight_async_reqs\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_remote_worker_restarts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d80344d003f4d80494d00544d805e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d800a4d00154d801f4d002a4d80344d003f4d80494d00544d805e652e\"\n      }\n    },\n    \"num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d08044d0a054d0c064d0e074d1008652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004d02014d04024d06034d08044d0a054d0c064d0e074d1008652e\"\n      }\n    },\n    \"num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d80114d00154d80184d001c4d801f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d80034d00074d800a4d000e4d80114d00154d80184d001c4d801f652e\"\n      }\n    },\n    \"num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d08044d0a054d0c064d0e074d1008652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004d02014d04024d06034d08044d0a054d0c064d0e074d1008652e\"\n      }\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d80034d80034d80034d80034d8003652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d80034d80034d80034d80034d80034d80034d80034d80034d8003652e\"\n      }\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d02014d02014d02014d02014d0201652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004d02014d02014d02014d02014d02014d02014d02014d0201652e\"\n      }\n    },\n    \"num_env_steps_sampled_throughput_per_sec\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847407e8c3f777f72f947407ace632bd5e90b47407e121e9a3173d147407d3ee39b04672247407df0f94713a861652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059573000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474072588e292f52f2474077609d33fbb1f347407ee94042c0e40a47407cf98b48080c1f47407e8c3f777f72f947407ace632bd5e90b47407e121e9a3173d147407d3ee39b04672247407df0f94713a861652e\"\n      }\n    },\n    \"num_env_steps_trained_throughput_per_sec\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474061979ffa88411247405edffff03417d8474061514ac43a318e474060d7a55cb3adae4740613e3420eebfd3652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059573000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847000000000000000047405aecfe35042f3f474061cd2f4b03a7e6474060afb5ece934b2474061979ffa88411247405edffff03417d8474061514ac43a318e474060d7a55cb3adae4740613e3420eebfd3652e\"\n      }\n    },\n    \"timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d80114d00154d80184d001c4d801f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d80034d00074d800a4d000e4d80114d00154d80184d001c4d801f652e\"\n      }\n    },\n    \"num_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d02014d02014d02014d02014d0201652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004d02014d02014d02014d02014d02014d02014d02014d0201652e\"\n      }\n    },\n    \"agent_timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d80344d003f4d80494d00544d805e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d800a4d00154d801f4d002a4d80344d003f4d80494d00544d805e652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428898989898989898989652e\"\n      }\n    },\n    \"episodes_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b054b064b074b084b09652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b09652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473ffd97ecc0000000474000cf0940000000473ffe0c9c80000000473ffed8b940000000473ffe2e1ec0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059573000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740087306200000004740034af880000000473ffd3edd80000000473fff3499c0000000473ffd97ecc0000000474000cf0940000000473ffe0c9c80000000473ffed8b940000000473ffe2e1ec0000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402630ec2800000047402a64ae7800000047402e26420800000047403100ac98000000474032e38e84000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059573000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474008730620000000474015deff5000000047401d2eb6b00000004740227dee9000000047402630ec2800000047402a64ae7800000047402e26420800000047403100ac98000000474032e38e84000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402630ec2800000047402a64ae7800000047402e26420800000047403100ac98000000474032e38e84000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059573000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474008730620000000474015deff5000000047401d2eb6b00000004740227dee9000000047402630ec2800000047402a64ae7800000047402e26420800000047403100ac98000000474032e38e84000000652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b054b064b074b084b09652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b084b09652e\"\n      }\n    },\n    \"info/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d80114d00154d80184d001c4d801f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d80034d00074d800a4d000e4d80114d00154d80184d001c4d801f652e\"\n      }\n    },\n    \"info/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d08044d0a054d0c064d0e074d1008652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004d02014d04024d06034d08044d0a054d0c064d0e074d1008652e\"\n      }\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d80344d003f4d80494d00544d805e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d800a4d00154d801f4d002a4d80344d003f4d80494d00544d805e652e\"\n      }\n    },\n    \"info/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d08044d0a054d0c064d0e074d1008652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004d02014d04024d06034d08044d0a054d0c064d0e074d1008652e\"\n      }\n    },\n    \"sampler_results/episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059573000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000652e\"\n      }\n    },\n    \"sampler_results/episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059573000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000652e\"\n      }\n    },\n    \"sampler_results/episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059573000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000652e\"\n      }\n    },\n    \"sampler_results/episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059573000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000477ff8000000000000652e\"\n      }\n    },\n    \"sampler_results/episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"sampler_results/num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740a13a1cac0831274740a1136f1a9fbe774740a0b703958106254740a07ed5810624dd4740a0493ef9db22d1652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059573000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a7d8cdd2f1a9fc4740a547d5810624dd4740a2e7a24dd2f1aa4740a1f40f5c28f5c34740a13a1cac0831274740a1136f1a9fbe774740a0b703958106254740a07ed5810624dd4740a0493ef9db22d1652e\"\n      }\n    },\n    \"timers/sample_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474095b4e04189374c474095808f5c28f5c34740954a33333333334740953ae45a1cac084740951f2d0e560419652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059573000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474097813a5e353f7d474098249fbe76c8b447409688f8d4fdf3b64740963d52f1a9fbe7474095b4e04189374c474095808f5c28f5c34740954a33333333334740953ae45a1cac084740951f2d0e560419652e\"\n      }\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d80114d00154d80184d001c4d801f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d80034d00074d800a4d000e4d80114d00154d80184d001c4d801f652e\"\n      }\n    },\n    \"counters/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d08044d0a054d0c064d0e074d1008652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004d02014d04024d06034d08044d0a054d0c064d0e074d1008652e\"\n      }\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d80344d003f4d80494d00544d805e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d800a4d00154d801f4d002a4d80344d003f4d80494d00544d805e652e\"\n      }\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d08044d0a054d0c064d0e074d1008652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004d02014d04024d06034d08044d0a054d0c064d0e074d1008652e\"\n      }\n    },\n    \"perf/cpu_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308333333333363554094869452946807680d4308dedddddddd3d504094869452946807680d43084444444444444f4094869452946807680d43087777777777b7504094869452946807680d430800000000007055409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ae47e17a14ae474094869452946807680d4308efeeeeeeee2e514094869452946807680d4308444444444484504094869452946807680d4308111111111151504094869452946807680d4308333333333363554094869452946807680d4308dedddddddd3d504094869452946807680d43084444444444444f4094869452946807680d43087777777777b7504094869452946807680d430800000000007055409486945294652e\"\n      }\n    },\n    \"perf/ram_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308666666666606574094869452946807680d4308656666666606574094869452946807680d4308656666666606574094869452946807680d4308abaaaaaaaa0a574094869452946807680d4308cdcccccccc0c57409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243081e85eb51b8fe564094869452946807680d4308656666666606574094869452946807680d4308444444444404574094869452946807680d4308444444444404574094869452946807680d4308666666666606574094869452946807680d4308656666666606574094869452946807680d4308656666666606574094869452946807680d4308abaaaaaaaa0a574094869452946807680d4308cdcccccccc0c57409486945294652e\"\n      }\n    },\n    \"info/last_target_update_ts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d80114d00154d80184d001c4d801f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d00074d800a4d000e4d80114d00154d80184d001c4d801f652e\"\n      }\n    },\n    \"info/num_target_updates\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b044b054b064b074b08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b08652e\"\n      }\n    },\n    \"timers/load_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fe0cccccccccccd473fe0d4fdf3b645a2473fe0dd2f1a9fbe77473fe0e5604189374c473fe0dd2f1a9fbe77652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fe116872b020c4a473fe0bc6a7ef9db23473fe0b4395810624e473fe0cccccccccccd473fe0d4fdf3b645a2473fe0dd2f1a9fbe77473fe0e5604189374c473fe0dd2f1a9fbe77652e\"\n      }\n    },\n    \"timers/load_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847411dfdbbb53f7cee47411de9bd374bc6a847411de362d604189347411dd08dd810624e47411de2cf1db22d0e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847411d7c57c5a1cac147411e21a2916872b047411e2527d810624e47411dfdbbb53f7cee47411de9bd374bc6a847411de362d604189347411dd08dd810624e47411de2cf1db22d0e652e\"\n      }\n    },\n    \"timers/learn_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474052004189374bc74740518d1eb851eb854740515ae147ae147b474051277ced916873474050f4189374bc6a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474057615810624dd3474053ff8d4fdf3b64474052b0624dd2f1aa474052004189374bc74740518d1eb851eb854740515ae147ae147b474051277ced916873474050f4189374bc6a652e\"\n      }\n    },\n    \"timers/learn_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740abfe4bc6a7ef9e4740acb5e2d0e560424740ad090a3d70a3d74740ad5ffd70a3d70a4740adb9147ae147ae652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740a58d7be76c8b444740a93288b43958104740aaf67c6a7ef9db4740abfe4bc6a7ef9e4740acb5e2d0e560424740ad090a3d70a3d74740ad5ffd70a3d70a4740adb9147ae147ae652e\"\n      }\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474030feb851eb851f4740314d0e560418934740313126e978d4fe474031d604189374bc474031770a3d70a3d7652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005956a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402f94fdf3b645a247403190624dd2f1aa474030ebc6a7ef9db2474030feb851eb851f4740314d0e560418934740313126e978d4fe474031d604189374bc474031770a3d70a3d7652e\"\n      }\n    },\n    \"counters/last_target_update_ts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d80114d00154d80184d001c4d801f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d00074d800a4d000e4d80114d00154d80184d001c4d801f652e\"\n      }\n    },\n    \"counters/num_target_updates\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b044b054b064b074b08652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059532000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b014b024b034b044b054b064b074b08652e\"\n      }\n    },\n    \"info/learner/agent_0/mean_td_error\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000023ed164094869452946807680d4308000000800147174094869452946807680d4308000000e0d00a174094869452946807680d4308000000806138154094869452946807680d4308000000204f3315409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000c0af1d164094869452946807680d430800000060302a164094869452946807680d4308000000606dd3164094869452946807680d43080000000023ed164094869452946807680d4308000000800147174094869452946807680d4308000000e0d00a174094869452946807680d4308000000806138154094869452946807680d4308000000204f3315409486945294652e\"\n      }\n    },\n    \"info/learner/agent_0/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d430800000000008055409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d430800000000008055409486945294652e\"\n      }\n    },\n    \"info/learner/agent_0/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000104094869452946807680d4308000000000000144094869452946807680d4308000000000000184094869452946807680d43080000000000001c4094869452946807680d430800000000000020409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000f03f94869452946807680d4308000000000000004094869452946807680d4308000000000000084094869452946807680d4308000000000000104094869452946807680d4308000000000000144094869452946807680d4308000000000000184094869452946807680d43080000000000001c4094869452946807680d430800000000000020409486945294652e\"\n      }\n    },\n    \"info/learner/agent_0/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000084094869452946807680d4308000000000000104094869452946807680d4308000000000000144094869452946807680d4308000000000000184094869452946807680d43080000000000001c409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000f03f94869452946807680d4308000000000000004094869452946807680d4308000000000000084094869452946807680d4308000000000000104094869452946807680d4308000000000000144094869452946807680d4308000000000000184094869452946807680d43080000000000001c409486945294652e\"\n      }\n    },\n    \"info/learner/agent_1/mean_td_error\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000060b2c6124094869452946807680d4308000000e0c62a144094869452946807680d430800000060de9f154094869452946807680d430800000000960e164094869452946807680d4308000000e093a615409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000078b70f4094869452946807680d4308000000c03868104094869452946807680d4308000000004e71124094869452946807680d430800000060b2c6124094869452946807680d4308000000e0c62a144094869452946807680d430800000060de9f154094869452946807680d430800000000960e164094869452946807680d4308000000e093a615409486945294652e\"\n      }\n    },\n    \"info/learner/agent_1/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d430800000000008055409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d430800000000008055409486945294652e\"\n      }\n    },\n    \"info/learner/agent_1/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000104094869452946807680d4308000000000000144094869452946807680d4308000000000000184094869452946807680d43080000000000001c4094869452946807680d430800000000000020409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000f03f94869452946807680d4308000000000000004094869452946807680d4308000000000000084094869452946807680d4308000000000000104094869452946807680d4308000000000000144094869452946807680d4308000000000000184094869452946807680d43080000000000001c4094869452946807680d430800000000000020409486945294652e\"\n      }\n    },\n    \"info/learner/agent_1/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000084094869452946807680d4308000000000000104094869452946807680d4308000000000000144094869452946807680d4308000000000000184094869452946807680d43080000000000001c409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000f03f94869452946807680d4308000000000000004094869452946807680d4308000000000000084094869452946807680d4308000000000000104094869452946807680d4308000000000000144094869452946807680d4308000000000000184094869452946807680d43080000000000001c409486945294652e\"\n      }\n    },\n    \"info/learner/agent_2/mean_td_error\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000040dca4134094869452946807680d4308000000a0d113134094869452946807680d4308000000405644144094869452946807680d4308000000206a61144094869452946807680d43080000000082d815409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000602e08114094869452946807680d4308000000a01f08114094869452946807680d4308000000203638134094869452946807680d430800000040dca4134094869452946807680d4308000000a0d113134094869452946807680d4308000000405644144094869452946807680d4308000000206a61144094869452946807680d43080000000082d815409486945294652e\"\n      }\n    },\n    \"info/learner/agent_2/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d430800000000008055409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d4308000000000080554094869452946807680d430800000000008055409486945294652e\"\n      }\n    },\n    \"info/learner/agent_2/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000104094869452946807680d4308000000000000144094869452946807680d4308000000000000184094869452946807680d43080000000000001c4094869452946807680d430800000000000020409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000f03f94869452946807680d4308000000000000004094869452946807680d4308000000000000084094869452946807680d4308000000000000104094869452946807680d4308000000000000144094869452946807680d4308000000000000184094869452946807680d43080000000000001c4094869452946807680d430800000000000020409486945294652e\"\n      }\n    },\n    \"info/learner/agent_2/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000084094869452946807680d4308000000000000104094869452946807680d4308000000000000144094869452946807680d4308000000000000184094869452946807680d43080000000000001c409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000f03f94869452946807680d4308000000000000004094869452946807680d4308000000000000084094869452946807680d4308000000000000104094869452946807680d4308000000000000144094869452946807680d4308000000000000184094869452946807680d43080000000000001c409486945294652e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000407737244094869452946807680d430800000080e620244094869452946807680d4308000000a0622f244094869452946807680d4308000000207845244094869452946807680d430800000040312224409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000040a0d6234094869452946807680d4308000000a0b043244094869452946807680d4308000000c0c30d244094869452946807680d4308000000407737244094869452946807680d430800000080e620244094869452946807680d4308000000a0622f244094869452946807680d4308000000207845244094869452946807680d430800000040312224409486945294652e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/actor_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000020cc9710c094869452946807680d4308000000608a8110c094869452946807680d4308000000c04ab310c094869452946807680d430800000080f8fa10c094869452946807680d4308000000403dd710c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000ba580fc094869452946807680d430800000080669310c094869452946807680d4308000000e0d73510c094869452946807680d430800000020cc9710c094869452946807680d4308000000608a8110c094869452946807680d4308000000c04ab310c094869452946807680d430800000080f8fa10c094869452946807680d4308000000403dd710c09486945294652e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/critic_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000c0e2e9134094869452946807680d4308000000402094134094869452946807680d43080000004011ce134094869452946807680d4308000000801cf5114094869452946807680d4308000000c0355112409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000040b21d144094869452946807680d4308000000e0ef84134094869452946807680d4308000000c06c2e144094869452946807680d4308000000c0e2e9134094869452946807680d4308000000402094134094869452946807680d43080000004011ce134094869452946807680d4308000000801cf5114094869452946807680d4308000000c0355112409486945294652e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/alpha_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000008000a382bf94869452946807680d43080000004009be88bf94869452946807680d43080000004009048fbf94869452946807680d4308000000c08bb092bf94869452946807680d4308000000405ea895bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d430800000000a2e668bf94869452946807680d430800000020f0a578bf94869452946807680d43080000008000a382bf94869452946807680d43080000004009be88bf94869452946807680d43080000004009048fbf94869452946807680d4308000000c08bb092bf94869452946807680d4308000000405ea895bf9486945294652e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430407c57f3f94869452946807680d430461b17f3f94869452946807680d4304bc9d7f3f94869452946807680d4304188a7f3f94869452946807680d430474767f3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595ef000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d430458ec7f3f94869452946807680d4304aed87f3f94869452946807680d430407c57f3f94869452946807680d430461b17f3f94869452946807680d4304bc9d7f3f94869452946807680d4304188a7f3f94869452946807680d430474767f3f9486945294652e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/log_alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430459fe6bba94869452946807680d430401579dba94869452946807680d43043eaec4ba94869452946807680d43045e06ecba94869452946807680d43048fb009bb9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595ef000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000000094869452946807680d430451499db994869452946807680d430454531dba94869452946807680d430459fe6bba94869452946807680d430401579dba94869452946807680d43043eaec4ba94869452946807680d43045e06ecba94869452946807680d43048fb009bb9486945294652e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/target_entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595ef000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c09486945294652e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/policy_t\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000020518892bf94869452946807680d430800000000cead62bf94869452946807680d43080000006093f59fbf94869452946807680d430800000080799f77bf94869452946807680d4308000000803c0d72bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000060fed98d3f94869452946807680d4308000000a000c9a83f94869452946807680d43080000002029b686bf94869452946807680d430800000020518892bf94869452946807680d430800000000cead62bf94869452946807680d43080000006093f59fbf94869452946807680d430800000080799f77bf94869452946807680d4308000000803c0d72bf9486945294652e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/mean_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000006dba93f94869452946807680d4308000000203426b33f94869452946807680d4308000000008a91b93f94869452946807680d4308000000e0b1f1c03f94869452946807680d4308000000c0cef1c53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000040075d483f94869452946807680d4308000000c035428f3f94869452946807680d43080000002011ee9f3f94869452946807680d43080000000006dba93f94869452946807680d4308000000203426b33f94869452946807680d4308000000008a91b93f94869452946807680d4308000000e0b1f1c03f94869452946807680d4308000000c0cef1c53f9486945294652e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/max_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000080992cb23f94869452946807680d4308000000c02ee4b93f94869452946807680d4308000000001061c33f94869452946807680d430800000060c33ecb3f94869452946807680d430800000000c1e4d03f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000400743773f94869452946807680d4308000000a0f9d4953f94869452946807680d4308000000a01ddea33f94869452946807680d430800000080992cb23f94869452946807680d4308000000c02ee4b93f94869452946807680d4308000000001061c33f94869452946807680d430800000060c33ecb3f94869452946807680d430800000000c1e4d03f9486945294652e\"\n      }\n    },\n    \"info/learner/agent_0/learner_stats/min_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e0b9cca33f94869452946807680d4308000000a05d59ac3f94869452946807680d4308000000809bc1b13f94869452946807680d4308000000e09c15b63f94869452946807680d4308000000007316ba3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a0b32f72bf94869452946807680d4308000000e06f69853f94869452946807680d4308000000204d26983f94869452946807680d4308000000e0b9cca33f94869452946807680d4308000000a05d59ac3f94869452946807680d4308000000809bc1b13f94869452946807680d4308000000e09c15b63f94869452946807680d4308000000007316ba3f9486945294652e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000020db11244094869452946807680d4308000000401603244094869452946807680d430800000020d023244094869452946807680d4308000000c0703d244094869452946807680d430800000020751d24409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000019dd234094869452946807680d4308000000801213244094869452946807680d4308000000a05f3f244094869452946807680d430800000020db11244094869452946807680d4308000000401603244094869452946807680d430800000020d023244094869452946807680d4308000000c0703d244094869452946807680d430800000020751d24409486945294652e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/actor_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a0a24b10c094869452946807680d4308000000609d4510c094869452946807680d4308000000e003a310c094869452946807680d4308000000e042f410c094869452946807680d4308000000809cd010c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a029680fc094869452946807680d4308000000c0d82d10c094869452946807680d4308000000e0759510c094869452946807680d4308000000a0a24b10c094869452946807680d4308000000609d4510c094869452946807680d4308000000e003a310c094869452946807680d4308000000e042f410c094869452946807680d4308000000809cd010c09486945294652e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/critic_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000d655104094869452946807680d43080000006056280f4094869452946807680d430800000040396d104094869452946807680d4308000000006f31114094869452946807680d4308000000a006ff10409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000002078b70b4094869452946807680d430800000000ed780c4094869452946807680d430800000020691a104094869452946807680d430800000000d655104094869452946807680d43080000006056280f4094869452946807680d430800000040396d104094869452946807680d4308000000006f31114094869452946807680d4308000000a006ff10409486945294652e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/alpha_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000080758082bf94869452946807680d4308000000a0629988bf94869452946807680d4308000000e0d9f18ebf94869452946807680d430800000040c9a892bf94869452946807680d430800000080d3a295bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d430800000020e4aa68bf94869452946807680d43080000004029e278bf94869452946807680d430800000080758082bf94869452946807680d4308000000a0629988bf94869452946807680d4308000000e0d9f18ebf94869452946807680d430800000040c9a892bf94869452946807680d430800000080d3a295bf9486945294652e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430407c57f3f94869452946807680d430461b17f3f94869452946807680d4304bd9d7f3f94869452946807680d43041a8a7f3f94869452946807680d430477767f3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595ef000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d430458ec7f3f94869452946807680d4304afd87f3f94869452946807680d430407c57f3f94869452946807680d430461b17f3f94869452946807680d4304bd9d7f3f94869452946807680d43041a8a7f3f94869452946807680d430477767f3f9486945294652e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/log_alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304faff6bba94869452946807680d4304fa569dba94869452946807680d4304adabc4ba94869452946807680d4304da01ecba94869452946807680d4304b4ad09bb9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595ef000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000000094869452946807680d430450499db994869452946807680d4304944e1dba94869452946807680d4304faff6bba94869452946807680d4304fa569dba94869452946807680d4304adabc4ba94869452946807680d4304da01ecba94869452946807680d4304b4ad09bb9486945294652e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/target_entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595ef000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c09486945294652e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/policy_t\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000020b0c5adbf94869452946807680d430800000080e0c6933f94869452946807680d430800000060b19b913f94869452946807680d430800000040e1168ebf94869452946807680d4308000000809cbe973f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000060cc326fbf94869452946807680d430800000060068193bf94869452946807680d4308000000c05d567a3f94869452946807680d430800000020b0c5adbf94869452946807680d430800000080e0c6933f94869452946807680d430800000060b19b913f94869452946807680d430800000040e1168ebf94869452946807680d4308000000809cbe973f9486945294652e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/mean_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000200ea3ab3f94869452946807680d43080000002009a0b43f94869452946807680d4308000000e044febc3f94869452946807680d43080000004083d8c23f94869452946807680d430800000040bbebc63f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e0c4875e3f94869452946807680d4308000000a09d9f913f94869452946807680d4308000000c05e9aa13f94869452946807680d4308000000200ea3ab3f94869452946807680d43080000002009a0b43f94869452946807680d4308000000e044febc3f94869452946807680d43080000004083d8c23f94869452946807680d430800000040bbebc63f9486945294652e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/max_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000004030f7b33f94869452946807680d4308000000a0cfbbbc3f94869452946807680d430800000060a124c63f94869452946807680d430800000060ac38cb3f94869452946807680d4308000000400efed13f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000002045e9793f94869452946807680d4308000000e020fb973f94869452946807680d4308000000406d6ea83f94869452946807680d43080000004030f7b33f94869452946807680d4308000000a0cfbbbc3f94869452946807680d430800000060a124c63f94869452946807680d430800000060ac38cb3f94869452946807680d4308000000400efed13f9486945294652e\"\n      }\n    },\n    \"info/learner/agent_1/learner_stats/min_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000040c859a43f94869452946807680d4308000000e00480ad3f94869452946807680d4308000000e08e64b33f94869452946807680d4308000000a05d66b73f94869452946807680d4308000000601ce0bd3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000008ed765bf94869452946807680d4308000000004ea8893f94869452946807680d43080000000086d7993f94869452946807680d430800000040c859a43f94869452946807680d4308000000e00480ad3f94869452946807680d4308000000e08e64b33f94869452946807680d4308000000a05d66b73f94869452946807680d4308000000601ce0bd3f9486945294652e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000020990c244094869452946807680d430800000080b132244094869452946807680d430800000000fc00244094869452946807680d4308000000c0d221244094869452946807680d4308000000805d1924409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000020b7ed234094869452946807680d4308000000c06215244094869452946807680d4308000000c0ac30244094869452946807680d430800000020990c244094869452946807680d430800000080b132244094869452946807680d430800000000fc00244094869452946807680d4308000000c0d221244094869452946807680d4308000000805d1924409486945294652e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/actor_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e03b4610c094869452946807680d43080000008055a410c094869452946807680d4308000000e0c55610c094869452946807680d4308000000c086b410c094869452946807680d43080000008068c510c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a059b90fc094869452946807680d430800000020583810c094869452946807680d430800000020f47c10c094869452946807680d4308000000e03b4610c094869452946807680d43080000008055a410c094869452946807680d4308000000e0c55610c094869452946807680d4308000000c086b410c094869452946807680d43080000008068c510c09486945294652e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/critic_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000053e9104094869452946807680d4308000000c0c784104094869452946807680d4308000000c0f592114094869452946807680d430800000080fcb6114094869452946807680d4308000000a03e0a13409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a05c100e4094869452946807680d43080000004019d00d4094869452946807680d430800000020c4a2104094869452946807680d43080000000053e9104094869452946807680d4308000000c0c784104094869452946807680d4308000000c0f592114094869452946807680d430800000080fcb6114094869452946807680d4308000000a03e0a13409486945294652e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/alpha_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a0327b82bf94869452946807680d4308000000e02ed388bf94869452946807680d43080000008008bc8ebf94869452946807680d4308000000a0058f92bf94869452946807680d4308000000e0c79d95bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000e0bbad68bf94869452946807680d4308000000a0e2cf78bf94869452946807680d4308000000a0327b82bf94869452946807680d4308000000e02ed388bf94869452946807680d43080000008008bc8ebf94869452946807680d4308000000a0058f92bf94869452946807680d4308000000e0c79d95bf9486945294652e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430408c57f3f94869452946807680d430463b17f3f94869452946807680d4304be9d7f3f94869452946807680d43041c8a7f3f94869452946807680d43047b767f3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595ef000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000803f94869452946807680d430458ec7f3f94869452946807680d4304b0d87f3f94869452946807680d430408c57f3f94869452946807680d430463b17f3f94869452946807680d4304be9d7f3f94869452946807680d43041c8a7f3f94869452946807680d43047b767f3f9486945294652e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/log_alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b0fa6bba94869452946807680d43046a529dba94869452946807680d4304bca9c4ba94869452946807680d4304f9fdebba94869452946807680d43049aa909bb9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595ef000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000000094869452946807680d430451499db994869452946807680d43043c4d1dba94869452946807680d4304b0fa6bba94869452946807680d43046a529dba94869452946807680d4304bca9c4ba94869452946807680d4304f9fdebba94869452946807680d43049aa909bb9486945294652e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/target_entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595ef000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c09486945294652e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/policy_t\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000060da82753f94869452946807680d4308000000a099bfa63f94869452946807680d4308000000604e5757bf94869452946807680d4308000000405ce050bf94869452946807680d4308000000803c3d583f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000206beb89bf94869452946807680d430800000040dd5ea3bf94869452946807680d4308000000604d49a13f94869452946807680d430800000060da82753f94869452946807680d4308000000a099bfa63f94869452946807680d4308000000604e5757bf94869452946807680d4308000000405ce050bf94869452946807680d4308000000803c3d583f9486945294652e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/mean_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000202ee8ae3f94869452946807680d430800000020ab94b43f94869452946807680d4308000000809138bb3f94869452946807680d4308000000a0f71dc23f94869452946807680d43080000008038f4c63f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000080a38f753f94869452946807680d430800000020a385953f94869452946807680d430800000020ac38a43f94869452946807680d4308000000202ee8ae3f94869452946807680d430800000020ab94b43f94869452946807680d4308000000809138bb3f94869452946807680d4308000000a0f71dc23f94869452946807680d43080000008038f4c63f9486945294652e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/max_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000004022acb33f94869452946807680d4308000000e00b6ebc3f94869452946807680d430800000040a9f3c33f94869452946807680d430800000000328ccb3f94869452946807680d430800000060b6b2d13f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000008035a6853f94869452946807680d4308000000202d579c3f94869452946807680d4308000000c034f4a83f94869452946807680d43080000004022acb33f94869452946807680d4308000000e00b6ebc3f94869452946807680d430800000040a9f3c33f94869452946807680d430800000000328ccb3f94869452946807680d430800000060b6b2d13f9486945294652e\"\n      }\n    },\n    \"info/learner/agent_2/learner_stats/min_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000080e725a63f94869452946807680d4308000000601deead3f94869452946807680d430800000040b8cfb23f94869452946807680d43080000008002dcb73f94869452946807680d4308000000607290bb3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000004092695e3f94869452946807680d4308000000001ab48f3f94869452946807680d4308000000208bf99e3f94869452946807680d430800000080e725a63f94869452946807680d4308000000601deead3f94869452946807680d430800000040b8cfb23f94869452946807680d43080000008002dcb73f94869452946807680d4308000000607290bb3f9486945294652e\"\n      }\n    }\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059584010000000000008c267261792e747261696e2e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c125f636865636b706f696e745f636f6e666967948c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b0a8c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394681275628c135f636865636b706f696e745f726573756c7473945d948c195f6c61746573745f636865636b706f696e745f726573756c74944e75622e\"\n  }\n}"
    ]
  ],
  "runner_data": {
    "_earliest_stopping_actor": 46.158155916,
    "_actor_cleanup_timeout": 600,
    "_actor_force_cleanup_timeout": 10,
    "_reuse_actors": false,
    "_buffer_length": 1,
    "_buffer_min_time_s": 0.0,
    "_buffer_max_time_s": 100.0,
    "_max_pending_trials": 16,
    "_metric": null,
    "_total_time": 18.888893365859985,
    "_iteration": 350,
    "_has_errored": true,
    "_fail_fast": false,
    "_print_trial_errors": true,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_start_time": 1700201909.317238,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2023-11-16_22-18-29",
    "_checkpoint_period": "auto",
    "_trial_checkpoint_config": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "800595f2000000000000008c097261792e747261696e948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465944e8c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b0a8c11636865636b706f696e745f61745f656e64944e8c1a5f636865636b706f696e745f6b6565705f616c6c5f72616e6b73948c0a44455052454341544544948c1f5f636865636b706f696e745f75706c6f61645f66726f6d5f776f726b65727394680c75622e"
    },
    "_resumed": false,
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1700201909.317238,
    "timestamp": -Infinity
  }
}